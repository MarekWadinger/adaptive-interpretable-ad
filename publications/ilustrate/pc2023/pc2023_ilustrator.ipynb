{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413112fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_size(width=371.30264, fraction=1.4, subplots=(1, 1)):\n",
    "    \"\"\"Set figure dimensions to avoid scaling in LaTeX.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    width: float or string\n",
    "            Document width in points, or string of predined document type\n",
    "    fraction: float, optional\n",
    "            Fraction of the width which you wish the figure to occupy\n",
    "    subplots: array-like, optional\n",
    "            The number of rows and columns of subplots.\n",
    "    Returns\n",
    "    -------\n",
    "    fig_dim: tuple\n",
    "            Dimensions of figure in inches\n",
    "    \"\"\"\n",
    "    if width == 'thesis':\n",
    "        width_pt = 426.79135\n",
    "    elif width == 'beamer':\n",
    "        width_pt = 307.28987\n",
    "    else:\n",
    "        width_pt = width\n",
    "\n",
    "    # Width of figure (in pts)\n",
    "    fig_width_pt = width_pt * fraction\n",
    "    # Convert from pt to inches\n",
    "    inches_per_pt = 1 / 72.27\n",
    "\n",
    "    # Golden ratio to set aesthetic figure height\n",
    "    # https://disq.us/p/2940ij3\n",
    "    golden_ratio = (5**.5 - 1) / 2\n",
    "\n",
    "    # Figure width in inches\n",
    "    fig_width_in = fig_width_pt * inches_per_pt\n",
    "    # Figure height in inches\n",
    "    fig_height_in = fig_width_in * golden_ratio * (subplots[0] / subplots[1])\n",
    "\n",
    "    return (fig_width_in, fig_height_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588e971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 371.30264  # Minimum Thesis\n",
    "width = 307.28987  # Presentation 4:3\n",
    "width = 398.3386"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce9a963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"Times New Roman\",\n",
    "    \"axes.labelsize\": 10,\n",
    "    \"font.size\": 10,\n",
    "    \"legend.fontsize\": 10,\n",
    "    \"xtick.labelsize\": 10,\n",
    "    \"ytick.labelsize\": 10,\n",
    "})\n",
    "plt.rcParams.update({\"axes.grid\" : True})\n",
    "plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault[\"figure.figsize\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edb9f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import control\n",
    "import scipy.signal as sig\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "F1 = 0.8\n",
    "F2 = 0.1\n",
    "k11 = 1\n",
    "k22 = 1.3\n",
    "\n",
    "q0s = 0.2\n",
    "\n",
    "Q0s = np.arange(0.1,10,0.1)\n",
    "XData = []\n",
    "YData = []\n",
    "\n",
    "h2s = (q0s/k22)**2\n",
    "h1s = (q0s/k11)**2 + h2s\n",
    "\n",
    "K1 = k11*(1/(2*np.sqrt(h1s)))\n",
    "K2 = k22*(1/(2*np.sqrt(h2s)))\n",
    "\n",
    "A = np.array([[-K1/F1, 0], [K1/F2, -K2/F2]])\n",
    "B = np.array([[1/F1], [1/F2]])\n",
    "C = np.array([[1, 0], [0, 1]])\n",
    "D = np.array([[0], [0]])\n",
    "\n",
    "Ts = 0.5\n",
    "A_d, B_d, C_d, D_d, _ = sig.cont2discrete((A,B,C,D), Ts)\n",
    "Q = np.array([[1,0],[0,1]])\n",
    "R = np.array([[0.001]])\n",
    "\n",
    "K, S, E = control.dlqr(A_d,B_d,Q,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3330b378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(system, sim_time=300, faults=False):\n",
    "    t_out = []\n",
    "    y_ref = []\n",
    "    y_out = []\n",
    "    u_out = []\n",
    "    labels = []\n",
    "\n",
    "    q0_max = 10\n",
    "    q0_min = 0\n",
    "    lin_degradation = np.linspace(0, -10, sim_time)\n",
    "\n",
    "    q0s = 5\n",
    "    h2s = (q0s/k22)**2\n",
    "    h1s = (q0s/k11)**2 + h2s\n",
    "    h_ref = [h1s, h2s]\n",
    "    h_ode = h_ref\n",
    "    state = 0\n",
    "    fault_sensor = 0\n",
    "    fault_actuator = 0\n",
    "    for t in range(sim_time):\n",
    "      tspan = [t, t+Ts]\n",
    "      if t == 50:\n",
    "        q0s = 4\n",
    "        h2s = (q0s/k22)**2\n",
    "        h1s = (q0s/k11)**2 + h2s\n",
    "        h_ref = [h1s, h2s]\n",
    "        state = 1\n",
    "      elif t == 100:\n",
    "        q0s = 0.5\n",
    "        h2s = (q0s/k22)**2\n",
    "        h1s = (q0s/k11)**2 + h2s\n",
    "        h_ref = [h1s, h2s]\n",
    "        state = 2\n",
    "      elif t == 200:\n",
    "        q0s = 2.5\n",
    "        h2s = (q0s/k22)**2\n",
    "        h1s = (q0s/k11)**2 + h2s\n",
    "        h_ref = [h1s, h2s]\n",
    "        state = 3\n",
    "      labels.append(state)\n",
    "      \n",
    "      if t > 2:\n",
    "        if labels[-2] == -1 and labels[-2] != -1:  \n",
    "          labels[-1] = -1\n",
    "        if labels[-2] == -1 and labels[-2] != -1:  \n",
    "          labels[-1] = -1\n",
    "        \n",
    "      K = np.array([0.5, 0.1])\n",
    "      if faults:\n",
    "        fault_sensor = random.randint(1, 50)\n",
    "      else:\n",
    "        fault_sensor = 0\n",
    "      u = -K @ (np.array(h_ode if fault_sensor != 1 else h_ode*0) - np.array(h_ref))\n",
    "      q0 = u + q0s\n",
    "      q0 = max(min(q0, q0_max), q0_min)\n",
    "      if faults:\n",
    "        fault_actuator = random.randint(1, 50)\n",
    "      else:\n",
    "        fault_actuator = 0\n",
    "      if fault_actuator == 1:\n",
    "        q0 = q0*0.5\n",
    "      x_ode = solve_ivp(system, tspan, h_ode, args=(q0,), method=\"RK45\")\n",
    "      h_ode = x_ode.y[:,-1]\n",
    "      \n",
    "      if fault_sensor == 1:  \n",
    "        labels[-1] = -1\n",
    "      if fault_actuator == 1:  \n",
    "        labels[-1] = -1\n",
    "      y_out.append(h_ode if fault_sensor != 1 else h_ode*0)\n",
    "      y_ref.append(h_ref)\n",
    "      t_out.append(t)\n",
    "      u_out.append(q0)\n",
    "    y_ref = np.array(y_ref)\n",
    "    y_out = np.array(y_out)\n",
    "    t_out = np.array(t_out)\n",
    "    u_out = np.array(u_out)\n",
    "\n",
    "    return t_out, y_ref, y_out, u_out, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ced60d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import solve_ivp\n",
    "import random\n",
    "random.seed(40)\n",
    "def system(t, x, u):\n",
    "  h1, h2 = x\n",
    "  q0 = u\n",
    "\n",
    "  dh1_dt = q0/F1 - k11/F1 * np.sqrt(h1-h2)\n",
    "  dh2_dt = k11/F2 * np.sqrt(h1-h2) - k22/F2 * np.sqrt(h2)\n",
    "\n",
    "  return [dh1_dt, dh2_dt]\n",
    "\n",
    "q0_max = 10\n",
    "q0_min = 0\n",
    "t_out, y_ref, y_out_s, u_out_s, labels = simulate(system, sim_time=300, faults=False)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=set_size(subplots=(1,1)), sharex=True)\n",
    "axs[0].plot(t_out, y_out_s[:,0], label=r'$y_{\\mathrm{s}}$')\n",
    "axs[0].plot(t_out, y_ref[:,0], label=r'$y_{\\mathrm{ref}}$', linestyle=\":\")\n",
    "axs[0].set_ylabel('$y$')\n",
    "axs[0].set_title('a) Response of a System')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(t_out, u_out_s, label=r'$u_{\\mathrm{s}}$')\n",
    "color = next(axs[1]._get_lines.prop_cycler)\n",
    "axs[1].axhline(q0_max, **color, linestyle=\":\")\n",
    "axs[1].axhline(q0_min, **color, linestyle=\":\")\n",
    "axs[1].set_xlabel('$t$')\n",
    "axs[1].set_ylabel('$u$')\n",
    "axs[1].set_title('b) Control Action')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.savefig(\"simulation.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d457014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import solve_ivp\n",
    "import random\n",
    "random.seed(40)\n",
    "def system_perturbed(t, x, u):\n",
    "  h1, h2 = x\n",
    "  q0 = u\n",
    "\n",
    "  dh1_dt = q0/F1 - k11/F1 * np.sqrt(h1-h2) + random.normalvariate(0,5)*1+h1/50\n",
    "  dh2_dt = k11/F2 * np.sqrt(h1-h2) - k22/F2 * np.sqrt(h2) + random.normalvariate(0,5)*1+h1/50\n",
    "\n",
    "  return [dh1_dt, dh2_dt]\n",
    "\n",
    "q0_max = 10\n",
    "q0_min = 0\n",
    "t_out, y_ref, y_out_r, u_out_r, labels = simulate(system_perturbed, sim_time=300, faults=True)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=set_size(subplots=(1,1)), sharex=True)\n",
    "axs[0].plot(t_out, y_out_r[:,0], label=r'$y_{\\mathrm{r}}$')\n",
    "axs[0].plot(t_out, y_ref[:,0], label=r'$y_{\\mathrm{ref}}$', linestyle=\":\")\n",
    "axs[0].set_ylabel('$y$')\n",
    "axs[0].set_title('a) Response of a System')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(t_out, u_out_r, label=r'$u_{\\mathrm{r}}$')\n",
    "color = next(axs[1]._get_lines.prop_cycler)\n",
    "axs[1].axhline(q0_max, **color, linestyle=\":\")\n",
    "axs[1].axhline(q0_min, **color, linestyle=\":\")\n",
    "axs[1].set_xlabel('$t$')\n",
    "axs[1].set_ylabel('$u$')\n",
    "axs[1].set_title('b) Control Action')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.savefig(\"real.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d82a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import solve_ivp\n",
    "import random\n",
    "random.seed(40)\n",
    "def system_perturbed(t, x, u):\n",
    "  h1, h2 = x\n",
    "  q0 = u\n",
    "\n",
    "  dh1_dt = q0/F1 - k11/F1 * np.sqrt(h1-h2) + random.normalvariate(0,5)*1+h1/50\n",
    "  dh2_dt = k11/F2 * np.sqrt(h1-h2) - k22/F2 * np.sqrt(h2) + random.normalvariate(0,5)*1+h1/50\n",
    "\n",
    "  return [dh1_dt, dh2_dt]\n",
    "q0_max = 10\n",
    "q0_min = 0\n",
    "t_out, y_ref, y_out, u_out, _ = simulate(system_perturbed, sim_time=300, faults=False)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=set_size(subplots=(1,1)), sharex=True)\n",
    "color = next(axs[0]._get_lines.prop_cycler)\n",
    "axs[0].plot(t_out, y_out[:,0], **color, label='$y^*$')\n",
    "axs[0].plot(t_out, y_out_r[:,0], label=r'$y_{\\mathrm{r}}$',\n",
    "            **color, alpha=0.25)\n",
    "axs[0].plot(t_out, y_ref[:,0], label=r'$y_{\\mathrm{ref}}$', linestyle=\":\")\n",
    "axs[0].scatter(t_out[np.array(labels) == -1], \n",
    "               y_out_r[:, 0][np.array(labels) == -1], \n",
    "               marker='x', color='red', label=r'$y_{\\mathrm{a}}$')\n",
    "axs[0].set_ylabel('$y$')\n",
    "axs[0].set_title('a) Response of a System')\n",
    "axs[0].legend()\n",
    "\n",
    "color = next(axs[1]._get_lines.prop_cycler)\n",
    "axs[1].plot(t_out, u_out, **color, label='$u^*$')\n",
    "axs[1].plot(t_out, u_out_r, label=r'$u_{\\mathrm{r}}$', **color, alpha=0.25)\n",
    "color = next(axs[1]._get_lines.prop_cycler)\n",
    "axs[1].axhline(q0_max, **color, linestyle=\":\")\n",
    "axs[1].axhline(q0_min, **color, linestyle=\":\")\n",
    "axs[1].set_xlabel('$t$')\n",
    "axs[1].set_ylabel('$u$')\n",
    "axs[1].set_title('b) Control Action')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.savefig(\"imagined.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5921244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',\n",
    "          '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "\n",
    "\n",
    "def get_cmap(Z):\n",
    "    return ListedColormap(colors[0:len(np.unique(Z))])\n",
    "\n",
    "\n",
    "X = np.array([u_out_r, y_out_r[:, 0]]).T\n",
    "y = labels\n",
    "X_train = X[0:200, :]\n",
    "X_test = X[201::, :]\n",
    "y_train = y[0:200]\n",
    "y_train = np.where(np.array(y_train) == -1, 4, y_train)\n",
    "y_test = y[201::]\n",
    "# Initialize KMeans with 3 clusters and fit the data\n",
    "unsupervised = IsolationForest(contamination=0.05, random_state=40)  # nu=outliers_fraction)\n",
    "unsupervised.fit(X_train)\n",
    "\n",
    "# Initialize DecisionTreeClassifier and fit the data\n",
    "supervised = DecisionTreeClassifier(random_state=10, max_depth=4)\n",
    "supervised = LogisticRegressionCV(max_iter=1000,\n",
    "                                  class_weight={4: 3})\n",
    "supervised.fit(StandardScaler().fit_transform(X_train), y_train)\n",
    "y_pred = supervised.predict(StandardScaler().fit_transform(X_train))\n",
    "\n",
    "# Set up the figure with 2 rows and 2 columns\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=set_size(subplots=(2, 2)),\n",
    "                        sharex=True)\n",
    "\n",
    "# Plot the data with labels\n",
    "s = axs[0, 0].scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=ListedColormap(colors[0:4]))\n",
    "axs[0, 0].set_ylabel('$y$')\n",
    "axs[0, 0].set_title('a) Data with labels')\n",
    "legend1 = axs[0, 0].legend(\n",
    "    s.legend_elements()[0],\n",
    "    [r\"$y_{\\mathrm{ref}} = 40$\",\n",
    "     r\"$y_{\\mathrm{ref}} = 25$\",\n",
    "     r\"$y_{\\mathrm{ref}} = 0$\",\n",
    "     r\"$y_{\\mathrm{a}}$\"])\n",
    "axs[0, 0].add_artist(legend1)\n",
    "\n",
    "# Plot the data without labels\n",
    "axs[0, 1].scatter(X_train[:, 0], X_train[:, 1], c='grey')\n",
    "axs[0, 1].set_title('b) Data without labels')\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(0, 10, 200), np.linspace(0, 50, 200))\n",
    "Z = supervised.predict(StandardScaler().fit_transform(\n",
    "    np.c_[xx.ravel(), yy.ravel()]))\n",
    "Z = Z.reshape(xx.shape)\n",
    "# Plot the decision lines of the Decision Tree Classifier\n",
    "axs[1, 0].contourf(xx, yy, Z, alpha=0.4, cmap=get_cmap(Z))\n",
    "axs[1, 0].scatter(X_train[:, 0], X_train[:, 1], c=np.choose(y_pred, colors))\n",
    "axs[1, 0].set_title(f'c) {supervised.__class__.__name__}')\n",
    "axs[1, 0].set_xlabel('$u$')\n",
    "axs[1, 0].set_ylabel('$y$')\n",
    "\n",
    "Z = unsupervised.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "# Plot the data with cluster assignments\n",
    "axs[1, 1].scatter(X_train[:, 0], X_train[:, 1], c=np.choose(np.where(\n",
    "    unsupervised.predict(X_train) == -1, 0, unsupervised.predict(X_train)), ['#d62728', '#1f77b4']))\n",
    "axs[1, 1].imshow(\n",
    "    Z,\n",
    "    interpolation=\"nearest\",\n",
    "    extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "    cmap=ListedColormap(['#d62728', '#1f77b4']),\n",
    "    alpha=0.4,\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    ")\n",
    "axs[1, 1].set_title(f'd) {unsupervised.__class__.__name__}')\n",
    "axs[1, 1].set_xlabel('$u$')\n",
    "\n",
    "xlim = (0, 10)\n",
    "ylim = (0, 50)\n",
    "for ax in axs.flatten():\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(\"un_supervised.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebfc92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import random\n",
    "random.seed(40)\n",
    "from matplotlib.colors import ListedColormap\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',\n",
    "          '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "\n",
    "def get_cmap(Z):\n",
    "  return ListedColormap(colors[0:len(np.unique(Z))])\n",
    "\n",
    "\n",
    "# Add one sample from missing class to the test set\n",
    "y = np.where(np.array(y) == -1, 5, y)\n",
    "X_test = X\n",
    "y_test = X\n",
    "\n",
    "# Initialize DecisionTreeClassifier and fit the data\n",
    "supervised = make_pipeline(\n",
    "  StandardScaler(), \n",
    "  LogisticRegressionCV(max_iter=1000,\n",
    "                       class_weight={4: 3}))\n",
    "supervised.fit(X_train, y_train)\n",
    "\n",
    "from river import tree\n",
    "from river import linear_model\n",
    "from river import preprocessing\n",
    "from river import optim\n",
    "from river import anomaly\n",
    "\n",
    "class QuantileFilter(anomaly.QuantileFilter):\n",
    "  def __init__(self, anomaly_detector, q: float, protect_anomaly_detector=True):\n",
    "        super().__init__(\n",
    "            anomaly_detector=anomaly_detector,\n",
    "            protect_anomaly_detector=protect_anomaly_detector,\n",
    "            q=q\n",
    "        )\n",
    "  def predict_one(self, *args):\n",
    "    score = self.score_one(*args)\n",
    "    return score >= (self.quantile.get() or np.inf)\n",
    "online = (\n",
    "    preprocessing.MinMaxScaler() |\n",
    "    QuantileFilter(\n",
    "        anomaly.HalfSpaceTrees(\n",
    "            window_size=150,\n",
    "            n_trees=30,\n",
    "            height=10,\n",
    "            seed=40),\n",
    "        q=0.98\n",
    "    )\n",
    ")\n",
    "\n",
    "# Visualize data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=set_size(subplots=(2,2)),\n",
    "                        sharex=True)\n",
    "\n",
    "# Subplot 1: train data\n",
    "s = axs[0, 0].scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=ListedColormap(colors[0:4]))\n",
    "axs[0, 0].set_title(\"a) Train Data\")\n",
    "axs[0, 0].set_ylabel('$y$')\n",
    "legend1 = axs[0, 0].legend(\n",
    "    s.legend_elements()[0],\n",
    "    [r\"$y_{\\mathrm{ref}} = 40$\",\n",
    "     r\"$y_{\\mathrm{ref}} = 25$\",\n",
    "     r\"$y_{\\mathrm{ref}} = 0$\",\n",
    "     r\"$y_{\\mathrm{a}}$\"])\n",
    "axs[0, 0].add_artist(legend1)\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#9467bd', '#d62728', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(0, 10, 200), np.linspace(0, 50, 200))\n",
    "Z = unsupervised.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "# Plot the data with cluster assignments\n",
    "axs[1, 0].scatter(X[:, 0], X[:, 1], c=np.choose(np.where(\n",
    "    unsupervised.predict(X) == -1, 0, unsupervised.predict(X)), ['#d62728', '#1f77b4']))\n",
    "axs[1, 0].imshow(\n",
    "    Z,\n",
    "    interpolation=\"nearest\",\n",
    "    extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "    cmap=ListedColormap(['#d62728', '#1f77b4']),\n",
    "    alpha=0.4,\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    ")\n",
    "axs[1, 0].set_title('c) Batch Classifier')\n",
    "axs[1, 0].set_xlabel('$u$')\n",
    "axs[1, 0].set_ylabel('$y$')\n",
    "\n",
    "# Subplot 2: test data\n",
    "axs[0, 1].scatter(X[:, 0], X[:, 1], c=np.choose(y, colors))\n",
    "s3 = axs[0, 1].scatter(X[:, 0], X[:, 1], c=y, cmap=ListedColormap(colors[0:5]))\n",
    "axs[0, 1].set_title(\"b) All Data\")\n",
    "legend1 = axs[0, 1].legend(\n",
    "    s3.legend_elements()[0],\n",
    "    [r\"$y_{\\mathrm{ref}} = 40$\",\n",
    "     r\"$y_{\\mathrm{ref}} = 25$\",\n",
    "     r\"$y_{\\mathrm{ref}} = 0$\",\n",
    "     r\"$y_{\\mathrm{ref}} = 10$\",\n",
    "     r\"$y_{\\mathrm{a}}$\"])\n",
    "axs[0, 1].add_artist(legend1)\n",
    "\n",
    "# Subplot 4: online model\n",
    "y_online = []\n",
    "for x_, y_ in zip(X, y):\n",
    "  x_ = {i: v for i, v in enumerate(x_)}\n",
    "  y_pred = online.predict_one(x_)\n",
    "  y_online.append(y_pred) if y_pred is not None else y_online.append(0)\n",
    "  online.learn_one(x_, y_)\n",
    "axs[1, 1].scatter(X[:, 0], X[:, 1], c=np.choose(y_online, ['#1f77b4', '#d62728']))\n",
    "axs[1, 1].set_title('d) Online Classifier')\n",
    "axs[1, 1].set_xlabel('$u$')\n",
    "\n",
    "xlim = (0, 10)\n",
    "ylim = (0, 50)\n",
    "for ax in axs.flatten():\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "\n",
    "# plt.subplots_adjust(hspace=0.3, wspace=0.2)\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(\"online.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10de2e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import random\n",
    "random.seed(40)\n",
    "from matplotlib.colors import ListedColormap\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',\n",
    "          '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "\n",
    "def get_cmap(Z):\n",
    "  return ListedColormap(colors[0:len(np.unique(Z))])\n",
    "\n",
    "\n",
    "# Add one sample from missing class to the test set\n",
    "y = np.where(np.array(y) == -1, 5, y)\n",
    "X_test = X\n",
    "y_test = X\n",
    "\n",
    "# Initialize DecisionTreeClassifier and fit the data\n",
    "supervised = make_pipeline(\n",
    "  StandardScaler(), \n",
    "  LogisticRegressionCV(max_iter=1000,\n",
    "                       class_weight={4: 3}))\n",
    "supervised.fit(X_train, y_train)\n",
    "\n",
    "from river import tree\n",
    "from river import linear_model\n",
    "from river import preprocessing\n",
    "from river import optim\n",
    "from river import multiclass\n",
    "\n",
    "online = tree.HoeffdingAdaptiveTreeClassifier(\n",
    "    grace_period=10,\n",
    "    delta=1e-4,\n",
    "    seed=5\n",
    ")\n",
    "online = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    multiclass.OutputCodeClassifier(linear_model.LogisticRegression(optimizer=optim.SGD(.1), l2=2), code_size=4)\n",
    ")\n",
    "\n",
    "# Visualize data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=set_size(subplots=(2,2)),\n",
    "                        sharex=True)\n",
    "\n",
    "# Subplot 1: train data\n",
    "s = axs[0, 0].scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=ListedColormap(colors[0:4]))\n",
    "axs[0, 0].set_title(\"a) Train Data\")\n",
    "axs[0, 0].set_ylabel('$y$')\n",
    "legend1 = axs[0, 0].legend(\n",
    "    s.legend_elements()[0],\n",
    "    [r\"$y_{\\mathrm{ref}} = 40$\",\n",
    "     r\"$y_{\\mathrm{ref}} = 25$\",\n",
    "     r\"$y_{\\mathrm{ref}} = 0$\",\n",
    "     r\"$y_{\\mathrm{a}}$\"])\n",
    "axs[0, 0].add_artist(legend1)\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#9467bd', '#d62728', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "\n",
    "# Subplot 3: batch model\n",
    "y_pred = supervised.predict(X)\n",
    "axs[1, 0].scatter(X[:, 0], X[:, 1], c=np.choose(y_pred, colors))\n",
    "axs[1, 0].set_title('c) Batch Classifier (Decision Tree)')\n",
    "axs[1, 0].set_xlabel('$u$')\n",
    "axs[1, 0].set_ylabel('$y$')\n",
    "\n",
    "# Subplot 2: test data\n",
    "axs[0, 1].scatter(X[:, 0], X[:, 1], c=np.choose(y, colors))\n",
    "s3 = axs[0, 1].scatter(X[:, 0], X[:, 1], c=y, cmap=ListedColormap(colors[0:5]))\n",
    "axs[0, 1].set_title(\"b) All Data\")\n",
    "\n",
    "# Subplot 4: online model\n",
    "y_online = []\n",
    "for x_, y_ in zip(X, y):\n",
    "  x_ = {i: v for i, v in enumerate(x_)}\n",
    "  y_pred = online.predict_one(x_)\n",
    "  y_online.append(y_pred) if y_pred is not None else y_online.append(0)\n",
    "  online.learn_one(x_, y_)\n",
    "axs[1, 1].scatter(X[:, 0], X[:, 1], c=np.choose(y_online, colors))\n",
    "axs[1, 1].set_title('d) Online Classifier (Hoeffding Tree)')\n",
    "axs[1, 1].set_xlabel('$u$')\n",
    "\n",
    "xlim = (0, 10)\n",
    "ylim = (0, 50)\n",
    "for ax in axs.flatten():\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "\n",
    "# plt.subplots_adjust(hspace=0.3, wspace=0.2)\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(\"online.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c42183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# generate random data\n",
    "data = X_train[0:50,1]\n",
    "\n",
    "# initialize variables for Welford's algorithm\n",
    "n = 0\n",
    "mean = 0\n",
    "M2 = 0\n",
    "\n",
    "# calculate the mean and standard deviation using Welford's algorithm\n",
    "means = []\n",
    "stds = []\n",
    "for x in data:\n",
    "    n += 1\n",
    "    delta = x - mean\n",
    "    mean += delta / n\n",
    "    delta2 = x - mean\n",
    "    M2 += delta * delta2\n",
    "    if n > 1:\n",
    "        std = np.sqrt(M2 / (n - 1))\n",
    "    else:\n",
    "        std = 0\n",
    "    means.append(mean)\n",
    "    stds.append(std)\n",
    "\n",
    "# plot the data and the running mean and standard deviation\n",
    "fig, ax = plt.subplots(figsize=set_size())\n",
    "ax.plot(data, label=r'$y_{\\mathrm{r}}$')\n",
    "color = next(ax._get_lines.prop_cycler)\n",
    "ax.plot(means, label=r'$\\bar x_n$', **color)\n",
    "ax.plot(np.array(means) + np.array(stds), linestyle='--', \n",
    "        label=r'$\\bar x_n \\pm s_n$', **color)\n",
    "ax.plot(np.array(means) - np.array(stds), linestyle='--', **color)\n",
    "ax.legend()\n",
    "ax.set_xlabel('$t$')\n",
    "ax.set_ylabel('$y$')\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(\"welford.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1622db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def welford(data):\n",
    "    n = 0\n",
    "    mean = 0\n",
    "    M2 = 0\n",
    "    means = []\n",
    "    stds = []\n",
    "    for x in data:\n",
    "        n += 1\n",
    "        delta = x - mean\n",
    "        mean += delta/n\n",
    "        delta2 = x - mean\n",
    "        M2 += delta * delta2\n",
    "        var = M2/(n-1) if n > 1 else 0\n",
    "        std = np.sqrt(var)\n",
    "        means.append(mean)\n",
    "        stds.append(std)\n",
    "    return means, stds\n",
    "\n",
    "def inverse_welford(data, window_size):\n",
    "    window = data[:window_size]\n",
    "    window_mean = np.mean(window)\n",
    "    window_std = np.std(window)\n",
    "    means = [window_mean] * (window_size - 1)\n",
    "    stds = [window_std] * (window_size - 1)\n",
    "    for i, x in enumerate(data[window_size:], start=window_size):\n",
    "        prev = data[i - window_size]\n",
    "        next_ = x\n",
    "        window_mean = window_mean + (next_ - prev) / window_size\n",
    "        window_std = np.sqrt(((window_size - 2) * window_std ** 2 + (next_ - prev) ** 2 + (next_ - window_mean) * (prev - window_mean)) / (window_size - 1))\n",
    "        means.append(window_mean)\n",
    "        stds.append(window_std)\n",
    "    return means, stds\n",
    "\n",
    "# Generate example data\n",
    "data = X[:,1]\n",
    "window_size = 10\n",
    "# Calculate running means using Welford algorithm and inverse Welford algorithm\n",
    "welford_means, w_std = welford(data)\n",
    "inverse_welford_means, iw_std = inverse_welford(data, window_size=window_size)\n",
    "\n",
    "# Plot the data and running means\n",
    "fig, ax = plt.subplots(figsize=set_size())\n",
    "ax.plot(data, label=r'$y_{\\mathrm{r}}$',\n",
    "        alpha=0.25)\n",
    "ax.plot(welford_means, label=r'$\\bar x_n$ ($t_\\mathrm{e} = \\infty$)')\n",
    "ax.plot(inverse_welford_means, \n",
    "        label=fr'$\\bar x_n$ ($t_\\mathrm e = {window_size}$)')\n",
    "ax.legend()\n",
    "ax.set_xlabel('$t$')\n",
    "ax.set_ylabel('$y$')\n",
    "\n",
    "# ax.set_title('Running Means using Welford Algorithm with and without expiration')\n",
    "# Show the plot\n",
    "plt.savefig(\"welford_compare.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f150826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def welford(data):\n",
    "    n = 0\n",
    "    mean = 0\n",
    "    M2 = 0\n",
    "    means = []\n",
    "    stds = []\n",
    "    for x in data:\n",
    "        n += 1\n",
    "        delta = x - mean\n",
    "        mean += delta/n\n",
    "        delta2 = x - mean\n",
    "        M2 += delta * delta2\n",
    "        var = M2/(n-1) if n > 1 else 0\n",
    "        std = np.sqrt(var)\n",
    "        means.append(mean)\n",
    "        stds.append(std)\n",
    "    return means, stds\n",
    "\n",
    "def inverse_welford(data, window_size):\n",
    "    window = data[:window_size]\n",
    "    window_mean = np.mean(window)\n",
    "    window_std = np.std(window)\n",
    "    means = [window_mean] * (window_size - 1)\n",
    "    stds = [window_std] * (window_size - 1)\n",
    "    for i, x in enumerate(data[window_size:], start=window_size):\n",
    "        prev = data[i - window_size]\n",
    "        next_ = x\n",
    "        window_mean = window_mean + (next_ - prev) / window_size\n",
    "        window_std = np.sqrt(((window_size - 2) * window_std ** 2 + (next_ - prev) ** 2 + (next_ - window_mean) * (prev - window_mean)) / (window_size - 1))\n",
    "        means.append(window_mean)\n",
    "        stds.append(window_std)\n",
    "    return means, stds\n",
    "\n",
    "# Generate example data\n",
    "data = X[:,1]\n",
    "window_size = 10\n",
    "# Calculate running means using Welford algorithm and inverse Welford algorithm\n",
    "welford_means, w_std = welford(data)\n",
    "inverse_welford_means, iw_std = inverse_welford(data, window_size=window_size)\n",
    "\n",
    "# Plot the data and running means\n",
    "fig, ax = plt.subplots(figsize=set_size())\n",
    "ax.plot(data, label=r'$y_{\\mathrm{r}}$',\n",
    "        alpha=0.25)\n",
    "ax.plot(welford_means, label=r'$\\bar x_n$ ($t_\\mathrm{e} = \\infty$)',\n",
    "        alpha=0.25)\n",
    "ax.plot(inverse_welford_means, \n",
    "        label=fr'$\\bar x_n$ ($t_\\mathrm e = {window_size}$)')\n",
    "ax.legend()\n",
    "ax.set_xlabel('$t$')\n",
    "ax.set_ylabel('$y$')\n",
    "\n",
    "# ax.set_title('Running Means using Welford Algorithm with and without expiration')\n",
    "# Show the plot\n",
    "plt.savefig(\"welford_unstable.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14d491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "inverse_welford_means_prot = pd.read_csv(\n",
    "    \"inv_wel_prot_mean.csv\", index_col=0).iloc[:,0].values\n",
    "# Generate example data\n",
    "data = X[:,1]\n",
    "window_size = 10\n",
    "# Calculate running means using Welford algorithm and inverse Welford algorithm\n",
    "welford_means, w_std = welford(data)\n",
    "inverse_welford_means, iw_std = inverse_welford(data, window_size=window_size)\n",
    "\n",
    "# Plot the data and running means\n",
    "fig, ax = plt.subplots(figsize=set_size())\n",
    "ax.plot(data, label=r'$y_{\\mathrm{r}}$',\n",
    "        alpha=0.25)\n",
    "ax.plot(welford_means, label=r'$\\bar x_n$ ($t_\\mathrm{e} = \\infty$)',\n",
    "        alpha=0.25)\n",
    "ax.plot(inverse_welford_means, \n",
    "        label=fr'$\\bar x_n$ ($t_\\mathrm e = {window_size}$)')\n",
    "ax.plot(inverse_welford_means_prot, \n",
    "        label=fr'$\\bar x_n$ ($t_\\mathrm e = {window_size}$)*')\n",
    "ax.legend()\n",
    "ax.set_xlabel('$t$')\n",
    "ax.set_ylabel('$y$')\n",
    "# ax.set_title('Running Means using Welford Algorithm with and without expiration')\n",
    "# Show the plot\n",
    "plt.savefig(\"welford_compare_prot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b64335",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = data[-len(inverse_welford_means)::] - inverse_welford_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016138ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_welford_stds_prot = pd.read_csv(\n",
    "    \"inv_wel_prot_std.csv\", index_col=0).iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2129e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "random.seed(3)\n",
    "# Define the mean and standard deviation lists\n",
    "mean_list = [0]*3  # Example mean values\n",
    "std_list = random.sample(list(inverse_welford_stds_prot),3)   # Example standard deviation values\n",
    "std_list = random.sample(iw_std,4)   # Example standard deviation values\n",
    "\n",
    "# Generate a range of x-values\n",
    "x = np.linspace(-10, 10, 1000)\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots(figsize=set_size())\n",
    "\n",
    "# Iterate over mean and std lists\n",
    "for mean, std in zip(mean_list, std_list):\n",
    "    # Calculate the PDF values for the current mean and std\n",
    "    y = norm.pdf(x, mean, std)\n",
    "\n",
    "    # Plot the PDF curve\n",
    "    line, = ax.plot(x, y, label=fr\"$\\bar x_n={mean}, s_n={std:04.2f}$\")\n",
    "    # Get the color of the current plot\n",
    "    line_color = line.get_color()\n",
    "    # Calculate 3 sigma bounds\n",
    "    sigma = 3 * std\n",
    "    ax.axvline(mean + sigma, linestyle='--', color=line_color, alpha=0.5)\n",
    "    ax.axvline(mean - sigma, linestyle='--', color=line_color, alpha=0.5)\n",
    "\n",
    "# Set plot title and labels\n",
    "ax.set_xlabel(\"$X$\")\n",
    "ax.set_ylabel(\"PDF\")\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.savefig(\"sigmas.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803db1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "random.seed(3)\n",
    "# Define the mean and standard deviation lists\n",
    "mean_list = random.sample(inverse_welford_means,3)  # Example mean values\n",
    "std_list = random.sample(iw_std,3)   # Example standard deviation values\n",
    "\n",
    "# Generate a range of x-values\n",
    "x = np.linspace(-20, 45, 1000)\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots(figsize=set_size())\n",
    "\n",
    "# Iterate over mean and std lists\n",
    "for mean, std in zip(mean_list, std_list):\n",
    "    # Calculate the PDF values for the current mean and std\n",
    "    y_pdf = norm.pdf(x, mean, std)\n",
    "    y_cdf = norm.cdf(x, mean, std)\n",
    "\n",
    "    # Plot the PDF curve\n",
    "    line, = ax.plot(x, y_cdf, label=fr\"$\\bar x_n={mean:05.2f}, s_n={std:04.2f}$\")\n",
    "\n",
    "    # Calculate 3 sigma bounds\n",
    "    sigma = 3 * std\n",
    "\n",
    "    # Get the color of the current plot\n",
    "    line_color = line.get_color()\n",
    "\n",
    "    # Mark the probabilities with dashed horizontal lines\n",
    "    ax.axhline(0.9973, linestyle='--', color='k', alpha=0.5)\n",
    "    ax.axhline(1-0.9973, linestyle='--', color='k', alpha=0.5)\n",
    "    ax.axvline(norm.ppf(0.9973, mean, sigma), linestyle='--',\n",
    "               color=line_color, alpha=0.5)\n",
    "    ax.axvline(norm.ppf(1-0.9973, mean, sigma), linestyle='--',\n",
    "               color=line_color, alpha=0.5)\n",
    "\n",
    "# Set plot title and labels\n",
    "ax.set_xlabel(\"$X$\")\n",
    "ax.set_ylabel(\"CDF\")\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.savefig(\"cdf_ppf.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7027b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "# Generate data for the Gaussian distribution\n",
    "mu = 0\n",
    "sigma = 1\n",
    "x = np.linspace(mu - 4*sigma, mu + 4*sigma, 100)\n",
    "pdf = norm.pdf(x, mu, sigma)\n",
    "\n",
    "# Define the sigma levels for the vertical lines\n",
    "sigma_levels = [-3, -2, -1, 1, 2, 3]\n",
    "\n",
    "# Define the x-axis tick positions and labels for the sigma regions\n",
    "xtickvals = [mu + level*sigma for level in sigma_levels]\n",
    "xticklabels = [f'{level}$\\sigma$' for level in sigma_levels]\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=set_size())\n",
    "\n",
    "# Add the Gaussian probability density function trace\n",
    "ax.plot(x, pdf, label='PDF')\n",
    "\n",
    "# Add the vertical lines for the sigma levels\n",
    "for i, level in enumerate(sigma_levels):\n",
    "    color = next(ax._get_lines.prop_cycler) if i == 0 else color\n",
    "    ax.axvline(x=mu + level*sigma, **color, \n",
    "               linestyle='--', label='sigma' if i == 0 else None)\n",
    "    \n",
    "# Update the legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "new_handles, new_labels = [], []\n",
    "for handle, label in zip(handles, labels):\n",
    "    if label not in new_labels:\n",
    "        new_handles.append(handle)\n",
    "        new_labels.append(label)\n",
    "ax.legend(new_handles, new_labels)\n",
    "\n",
    "# Update the axis labels and tick positions\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('PDF')\n",
    "ax.set_xticks(xtickvals)\n",
    "ax.set_xticklabels(xticklabels)\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(\"sigmas.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5754d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "CodeCell": {
   "cm_config": {
    "indentUnit": 2
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
