Anomaly detection systems play a critical role in risk-averse systems by identifying abnormal patterns and adapting to novel expected patterns in data. These systems are particularly vital in the context of Internet of Things (IoT) devices that continuously stream high-fidelity data to control units.

In this rapidly evolving field, Chandola et al. conducted an influential review of prior research efforts across diverse application domains \cite{Chandola2009}.
Recent studies have underscored the need for holistic and tunable anomaly detection methods accessible to operators(\cite{Laptev2015, Kejariwal2015, Cook2020}).

Cook et al. denote substantial aspects that pose challenges to anomaly detection on IoT, including the temporal, spatial, and external context of measurements, multivariate characteristics, noise, and nonstationarity (\cite{Cook2020}). Feature engineering methods allow the encoding of contextual properties and enhance the performance (\cite{Fan2019}). However, extensive feature engineering may significantly increase dimensionality, requiring sizeable data storage and high computational resources (\cite{Talagala2021}).

Moreover, nonstationarity resulting from concept drift, an alternation in the pattern of data due to a change in statistical distribution, and change points, permanent changes to the system's state, represents a difficulty of a significant extent (\cite{Salehi2018}). In real-world scenarios, those changes are frequently unpredictable in their spatial and temporal characteristics and require systems with solid outlier rejection properties of intelligent tracking algorithms (\cite{Barbosa2019162}). Therefore, the ability of an anomaly detection method to adapt to changes in the data structure is crucial for long-term deployments. Nevertheless, as (\cite{Tartakovsky2013}) remarked, instantaneous detection is not an option, unless the false alarm risk is high

The former scalability problem now introduces a significant latency in detector adaptation (\cite{Wu2021}). Incremental learning methods allowed adaptation while restraining the storage of the whole dataset. The supervised operator-in-the-loop solution offered by Pannu et al. showed the detector's adaptation to data labeled on the flight (\cite{Pannu2012}).
Others approached the problem as sequential processing of bounded data buffers in univariate signals (\cite{Ahmad2017134}) and multivariate systems (\cite{Bosman201514}).

\subsection{Related Work}
Recent research has extended the scope of anomaly detection tasks to include root cause isolation governed by the development of explanatory methods capable of diagnosing and tracking faults across the system. Studies can be split into two groups of distinct approaches. The first group approaches explainability as the importance of individual features (\cite{Carletti2019}), (\cite{Nguyen2019}), (\cite{Amarasinghe2018}). Those studies allow an explanation of novelty by considering features independently. The second group uses statistical learning creating models explainable via probability. Yang et al. recently proposed a Bayesian network (BN) for fault detection and diagnosis tasks. Individual nodes of the network represent normally distributed variables, whereas the multiple regression model defines weights and relationships. Using the predefined structure of the BN, the authors propose an offline-trained model with online detection and diagnosis (\cite{Yang2022}). Offline training, however, as we wrote earlier, do not allow adaptation to expected novel pattern and, therefore, to our knowledge, is not suitable for long-term operation on real IoT devices.

This paper emphasizes the importance of combining adaptability in interpretable anomaly detection and proposes a method that addresses this challenge. Here we report the discovery and characterization of an adaptive anomaly detection method for streaming IoT data. The ability to diagnose multivariate data while providing root cause isolation, inherent in the univariate case, extends our previous contribution to the field as presented in (\cite{Wadinger2023}). The proposed algorithm represents a general method for a broad range of safety-critical systems where anomaly diagnosis and identification are paramount.

\subsection{Novelty of proposed approach}
The idea of using statistical outlier detection is well-established. We highlighting impactful contributions of (\cite{Yamanishi2002}) and (\cite{Yamanishi2004}). The authors propose a method for detecting anomalies in a time series. The method is based on the assumption that the continuous data is generated by a mixture of Gaussian distributions, while discrete data is modeled as histogram density. The authors solve the problem of change point detection as well. However, the adaptation system is unaware of such changes, making the moving window the only source of adaptation. Our self-supervised approach offers intelligent adaptation w.r.t. detected change points. Moreover, the author of the study does not attempt to isolate the root cause of the anomaly. We do so by computing the conditional probability of each measurement given the rest of the measurements and drawing limits defining the normal event probability threshold.

A limited number of studies have focused on adaptation and interpretability within the framework of anomaly detection. Two recent contributions in this area are (\cite{Steenwinckel2018}) and (\cite{Steenwinckel2021}). In (\cite{Steenwinckel2018}), the authors emphasize the importance of combining prior knowledge with a data-driven approach to achieve interpretability, particularly concerning root cause isolation. They propose a novel approach that involves extracting features based on knowledge graph pattern extraction and integrating them into the anomaly detection mechanism. This graph is subsequently transformed into a matrix, and adaptive region-of-interest extraction is performed using reinforcement learning techniques. To enhance interpretability, a Generative Adversarial Network (GAN) reconstructs a new graphical representation based on selected vectors. However, it's important to note that the validation of this idealized approach is pending further investigation. Lately, (\cite{Steenwinckel2021}) introduced a comprehensive framework for adaptive anomaly detection and root cause analysis in data streams. While the adaptation process is driven by user feedback, the specific mechanism remains undisclosed. The authors present an interpretation of their method through a user dashboard, featuring visualizations of raw data. This dashboard is capable of distinguishing between track-related problems and train-related issues, based on whether multiple trains at the same geographical location approach the anomaly. Meanwhile, our attempts aim to develop a self-supervised method capable of learning without human supervision which is often limited in time and poses significant delays in adaptation, while interpretation offers straightforward statistical reasoning and root cause isolation.

\subsection{Validation}\label{par:validation}
Two case studies show that our proposed method, based on dynamic joint normal distribution, has the capacity to explain novelties, isolate the root cause of anomalies, and allow adaptation to change points, advancing recently developed anomaly detection techniques for long-term deployment and cross-domain usage. We observe similar detection performance, albeit with lower scalability, when comparing our approach to well-established unsupervised anomaly detection methods in streamed data which create a bedrock for many state-of-the-art contributions, such as One-Class SVM (\cite{Amer2013, Liu2014, Krawczyk2015, Miao2019, Gozuacik2021}), and Half-Space Trees (\cite{Wetzig2019, Lyu2020}).

\subsection{Broader Impact}
Potential applications of the proposed method are in the field of energy storage systems, where the ability to detect anomalies and isolate their root cause, whilst adapting to changes in operation and environment, is crucial for the safety of the system. The proposed method is suitable for the existing infrastructure of the system, allowing detection and diagnosis of the system based on existing data streams. The dynamic process limits allow operational metrics monitoring, making potential early detection and prevention easier. Using adaptable methods without interpretability, on the other hand, may pose safety risks and lower total financial benefits, as the triggered false alarms may need to be thoroughly analyzed, resulting in prolonged downtimes.

\subsection{Paper Organization}
The paper is structured as follows: We begin with the problem and motivation in \textbf{Section \ref{Introduction}}, providing context. Next, in \textbf{Section \ref{Preliminaries}}, we lay the theoretical groundwork. Our proposed adaptive anomaly detection method is detailed in \textbf{Section \ref{Proposed Method}}. We then demonstrate real-world applications in \textbf{Section \ref{Case Study}}. Finally, we conclude the paper in \textbf{Section \ref{Conclusion}}, summarizing findings and discussing future research directions.

The main contribution of the proposed solution to the developed body of research is that it:
\begin{itemize}
\item Enriches interpretable anomaly detection with adaptive capabilities
\item Identifies systematic outliers and root cause
\item Uses self-learning approach on streamed data
\item Utilizes existing IT infrastructure
\item Establishes dynamic limits for signals
\end{itemize}
