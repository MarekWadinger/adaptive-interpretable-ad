@article{Chandola2009,
  author     = {Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
  title      = {Anomaly Detection: A Survey},
  year       = {2009},
  issue_date = {July 2009},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {41},
  number     = {3},
  issn       = {0360-0300},
  url        = {https://doi.org/10.1145/1541880.1541882},
  doi        = {10.1145/1541880.1541882},
  abstract   = {Anomaly detection is an important problem that has been researched within diverse research areas and application domains. Many anomaly detection techniques have been specifically developed for certain application domains, while others are more generic. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection. We have grouped existing techniques into different categories based on the underlying approach adopted by each technique. For each category we have identified key assumptions, which are used by the techniques to differentiate between normal and anomalous behavior. When applying a given technique to a particular domain, these assumptions can be used as guidelines to assess the effectiveness of the technique in that domain. For each category, we provide a basic anomaly detection technique, and then show how the different existing techniques in that category are variants of the basic technique. This template provides an easier and more succinct understanding of the techniques belonging to each category. Further, for each category, we identify the advantages and disadvantages of the techniques in that category. We also provide a discussion on the computational complexity of the techniques since it is an important issue in real application domains. We hope that this survey will provide a better understanding of the different directions in which research has been done on this topic, and how techniques developed in one area can be applied in domains for which they were not intended to begin with.},
  journal    = {ACM Comput. Surv.},
  month      = {jul},
  articleno  = {15},
  numpages   = {58},
  keywords   = {Anomaly detection, outlier detection}
}

@inproceedings{Laptev2015,
  author    = {Laptev, Nikolay and Amizadeh, Saeed and Flint, Ian},
  title     = {Generic and Scalable Framework for Automated Time-Series Anomaly Detection},
  year      = {2015},
  isbn      = {9781450336642},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2783258.2788611},
  doi       = {10.1145/2783258.2788611},
  abstract  = {This paper introduces a generic and scalable framework for automated anomaly detection on large scale time-series data. Early detection of anomalies plays a key role in maintaining consistency of person's data and protects corporations against malicious attackers. Current state of the art anomaly detection approaches suffer from scalability, use-case restrictions, difficulty of use and a large number of false positives. Our system at Yahoo, EGADS, uses a collection of anomaly detection and forecasting models with an anomaly filtering layer for accurate and scalable anomaly detection on time-series. We compare our approach against other anomaly detection systems on real and synthetic data with varying time-series characteristics. We found that our framework allows for 50-60{\%} improvement in precision and recall for a variety of use-cases. Both the data and the framework are being open-sourced. The open-sourcing of the data, in particular, represents the first of its kind effort to establish the standard benchmark for anomaly detection.},
  booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages     = {1939-1947},
  numpages  = {9},
  keywords  = {anomaly detection, time-series, scalable anomaly detection},
  location  = {Sydney, NSW, Australia},
  series    = {KDD '15}
}

@misc{Kejariwal2015,
  author    = {Kejariwal, Arun},
  title     = {Introducing practical and robust anomaly detection in a time series},
  publisher = {Twitter},
  year      = {2015},
  url       = {https://blog.twitter.com/engineering/en_us/a/2015/introducing-practical-and-robust-anomaly-detection-in-a-time-series}
}

@article{Cook2020,
  author  = {Cook, Andrew A. and Mısırlı, Göksel and Fan, Zhong},
  journal = {IEEE Internet of Things Journal},
  title   = {Anomaly Detection for IoT Time-Series Data: A Survey},
  year    = {2020},
  volume  = {7},
  number  = {7},
  pages   = {6481-6494},
  doi     = {10.1109/JIOT.2019.2958185}
}

@inproceedings{Pannu2012,
  author    = {Pannu, Husanbir S. and Liu, Jianguo and Fu, Song},
  booktitle = {2012 IEEE 31st Symposium on Reliable Distributed Systems},
  title     = {AAD: Adaptive Anomaly Detection System for Cloud Computing Infrastructures},
  year      = {2012},
  volume    = {},
  number    = {},
  pages     = {396-397},
  doi       = {10.1109/SRDS.2012.3}
}

@article{ZHANG2024121506,
  title    = {An unsupervised spatiotemporal fusion network augmented with random mask and time-relative information modulation for anomaly detection of machines with multiple measuring points},
  journal  = {Expert Systems with Applications},
  volume   = {237},
  pages    = {121506},
  year     = {2024},
  issn     = {0957-4174},
  doi      = {https://doi.org/10.1016/j.eswa.2023.121506},
  url      = {https://www.sciencedirect.com/science/article/pii/S0957417423020080},
  author   = {Kaiyu Zhang and Jinglong Chen and Chi-Guhn Lee and Shuilong He},
  keywords = {Anomaly detection, Spatiotemporal fusion, Signal modulation, Graph neural network, Transformer},
  abstract = {In industrial environments, individual sensor is easily affected by background noise, etc. In order to improve the reliability of anomaly detections, sensors are arranged at multiple measuring points to collect monitoring data of machines. However, under the coupling of vibration responses of multiple components of machines, the complex nonlinear relationship between monitoring data of multiple measuring points makes it difficult to achieve the best feature extraction and fusion effect, which reduces the accuracy of anomaly detection. To solve this problem, an unsupervised spatiotemporal fusion network augmented with random mask and time-relative information modulation is proposed. Firstly, we creatively propose random mask and modulated signal generation method based on mask index to learn the dependence of waveform and time dimension and achieve temporal dimension fusion of signals. Based on end-to-end training, modulated signals are also more conducive to spatial fusion. Then, to fully exploit the correlation between monitoring data of multiple measuring points and obtain the best spatial dimension fusion effect, a multi-head graph neural network based on self-attention weight matrix is carried out. Finally, we use transformer encoder to reconstruct the signal of each measuring point and obtain reconstruction error. Based on exponentially weighted moving average, anomaly detection threshold is obtained. Two anomaly detection experiments are conducted, and accuracy of 99.78\%, 99\% are achieved.}
}

@article{HUANG2023120799,
  title    = {A novel outlier detecting algorithm based on the outlier turning points},
  journal  = {Expert Systems with Applications},
  volume   = {231},
  pages    = {120799},
  year     = {2023},
  issn     = {0957-4174},
  doi      = {https://doi.org/10.1016/j.eswa.2023.120799},
  url      = {https://www.sciencedirect.com/science/article/pii/S0957417423013015},
  author   = {Jinlong Huang and Dongdong Cheng and Sulan Zhang},
  keywords = {Outlier detection, Local outliers, Outlier clusters, Outlier turning points},
  abstract = {Outlier detection is one of the hot research in data mining, and has been applied to various fields such as network anomaly detection, image abnormal analysis, etc. In recent years, many outlier detecting algorithms have been proposed. However, these outlier detecting algorithms are hard to effectively detect global outliers, local outliers and outlier clusters at the same time. In this paper, we propose a novel outlier detecting algorithm based on the following ideas: (1) the density distribution should not be changed dramatically on local area; (2) the ratio of the number of k nearest neighbors and the number of reverse k nearest neighbors should not be very big. Based on above ideas, the proposed algorithm aims to find outlier turning points, then regards all outlier turning points and its sparse neighbors as outliers. Furthermore, the proposed algorithm use natural neighbors to obtain the neighborhood parameter k adaptively. The formal analysis and extensive experiments demonstrate that this technique can detect global outliers, local outliers and outlier clusters without neighborhood parameter k.}
}

@article{Fan2019,
  title    = {Deep learning-based feature engineering methods for improved building energy prediction},
  journal  = {Applied Energy},
  volume   = {240},
  pages    = {35-45},
  year     = {2019},
  issn     = {0306-2619},
  doi      = {https://doi.org/10.1016/j.apenergy.2019.02.052},
  url      = {https://www.sciencedirect.com/science/article/pii/S0306261919303496},
  author   = {Cheng Fan and Yongjun Sun and Yang Zhao and Mengjie Song and Jiayuan Wang},
  keywords = {Building energy prediction, Data mining, Intelligent buildings, Unsupervised deep learning, Generative adversarial networks},
  abstract = {The enrichment in building operation data has enabled the development of advanced data-driven methods for building energy predictions. Existing studies mainly focused on the utilization of supervised learning techniques for model development, while overlooking the significance of feature engineering. Feature engineering are helpful for reducing data dimensionality, decreasing prediction model complexity, and tackling the problem of corrupted and noisy information. Considering that each building has unique operating characteristics, it is neither practical nor efficient to manually identify features for model developments. Data-driven feature engineering methods are thus needed to ensure the flexibility and generalization of building energy prediction models. Using operation data of real buildings, this paper investigates the performance of different deep learning techniques in automatically deriving high-quality features for building energy predictions. Three types of deep learning-based features are developed using fully-connected autoencoders, convolutional autoencoders and generative adversarial networks respectively. Their potentials in building energy predictions have been exploited and compared with conventional feature engineering methods. The study validates the usefulness of deep learning in enhancing building energy prediction performance. The research results help to automate and improve the predictive modeling process while bridging the knowledge gaps between deep learning and building professionals.}
}

@article{Talagala2021,
  author    = {Priyanga Dilini Talagala and Rob J. Hyndman and Kate Smith-Miles},
  title     = {Anomaly Detection in High-Dimensional Data},
  journal   = {Journal of Computational and Graphical Statistics},
  volume    = {30},
  number    = {2},
  pages     = {360-374},
  year      = {2021},
  publisher = {Taylor & Francis},
  doi       = {10.1080/10618600.2020.1807997},
  url       = {
               https://doi.org/10.1080/10618600.2020.1807997
               },
  eprint    = {

               https://doi.org/10.1080/10618600.2020.1807997
               }
}

@article{LI2024121304,
  title    = {Attribute-weighted outlier detection for mixed data based on parallel mutual information},
  journal  = {Expert Systems with Applications},
  volume   = {236},
  pages    = {121304},
  year     = {2024},
  issn     = {0957-4174},
  doi      = {https://doi.org/10.1016/j.eswa.2023.121304},
  url      = {https://www.sciencedirect.com/science/article/pii/S0957417423018067},
  author   = {Junli Li and Zhanfeng Liu},
  keywords = {Attribute weighting, Outlier detection, Mixed data, Parallel mutual information},
  abstract = {Outlier detection plays an important role in data mining because it can improve the performance of data analysis. Most outlier detection algorithms focus on numerical or categorical attributes; however, data typically have a mixture of numerical and categorical attributes. We addressed this problem by developing an attribute-weighted outlier detection algorithm, PMIOD, for high-dimensional and massive mixed data. The PMIOD algorithm adopts mutual information to measure attribute correlations and provides an attribute-weighting method for mixed data. Based on this, an attribute-weighted outlier detection method for mixed data was developed. Moreover, to improve the efficiency of mutual information computing for high-dimensional mixed data, the mutual information computing was parallelized on the Spark platform. We evaluated the proposed algorithm using ten UCI datasets and four synthetic datasets in comparison with widely used algorithms. Experiments were conducted to demonstrate the superiority of the results produced by the proposed algorithm.}
}

@article{DU2024121161,
  title    = {Generative adversarial nets for unsupervised outlier detection},
  journal  = {Expert Systems with Applications},
  volume   = {236},
  pages    = {121161},
  year     = {2024},
  issn     = {0957-4174},
  doi      = {https://doi.org/10.1016/j.eswa.2023.121161},
  url      = {https://www.sciencedirect.com/science/article/pii/S0957417423016639},
  author   = {Xusheng Du and Jiaying Chen and Jiong Yu and Shu Li and Qiyin Tan},
  abstract = {Outlier detection, also known as anomaly detection, has been a persistent and active research area for decades due to its wide range of applications in various fields. Many well-established methods have difficulty fitting the distribution of high-dimensional and complex data, making it difficult to detect outliers that have a low degree of deviation. To address this problem, we combine the distribution fitting capability of generative adversarial nets (GANs) with the specificity of the outlier detection problem and propose a GAN-based unsupervised outlier detection (GUOD) method. In a real dataset mixed with normal objects and outliers, the generator of GANs prefers to fit the distribution of the majority of normal objects to minimize the error; as a result, the generated fake data can be used as an augmentation of normal objects. Next, fake “normal objects” are used to train the autoencoder. Finally, the real data are fed into the autoencoder for one forward propagation, and the reconstruction error of the object is used as its own outlier factor. The top-n objects with the largest reconstruction errors are considered outliers. Extensive experiments are conducted on eight real-world datasets, and the results show that the GUOD method performs better than ten other state-of-the-art algorithms.}
}

@article{Salehi2018,
  author     = {Salehi, Mahsa and Rashidi, Lida},
  title      = {A Survey on Anomaly Detection in Evolving Data: [With Application to Forest Fire Risk Prediction]},
  year       = {2018},
  issue_date = {June 2018},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {20},
  number     = {1},
  issn       = {1931-0145},
  url        = {https://doi.org/10.1145/3229329.3229332},
  doi        = {10.1145/3229329.3229332},
  abstract   = {Traditionally most of the anomaly detection algorithms have been designed for 'static' datasets, in which all the observations are available at one time. In non-stationary environments on the other hand, the same algorithms cannot be applied as the underlying data distributions change constantly and the same models are not valid. Hence, we need to devise adaptive models that take into account the dynamically changing characteristics of environments and detect anomalies in 'evolving' data. Over the last two decades, many algorithms have been proposed to detect anomalies in evolving data. Some of them consider scenarios where a sequence of objects (called data streams) with one or multiple features evolves over time. Whereas the others concentrate on more complex scenarios, where streaming objects with one or multiple features have causal/non-causal relationships with each other. The latter can be represented as evolving graphs. In this paper, we categorize existing strategies for detecting anomalies in both scenarios including the state-of-the-art techniques. Since label information is mostly unavailable in real-world applications when data evolves, we review the unsupervised approaches in this paper. We then present an interesting application example, i.e., forest re risk prediction, and conclude the paper with future research directions in this eld for researchers and industry.},
  journal    = {SIGKDD Explor. Newsl.},
  month      = {may},
  pages      = {13-23},
  numpages   = {11}
}

@article{Barbosa2019162,
  title    = {DyClee: Dynamic clustering for tracking evolving environments},
  journal  = {Pattern Recognition},
  volume   = {94},
  pages    = {162-186},
  year     = {2019},
  issn     = {0031-3203},
  doi      = {https://doi.org/10.1016/j.patcog.2019.05.024},
  url      = {https://www.sciencedirect.com/science/article/pii/S0031320319301992},
  author   = {Nathalie {Barbosa Roa} and Louise Travé-Massuyès and Victor H. Grisales-Palacio},
  keywords = {Dynamic clustering, Data mining, On-line learning, Time-series, Data streams, Multi-density clustering},
  abstract = {Evolving environments challenge researchers with non stationary data flows where the concepts – or states – being tracked can change over time. This requires tracking algorithms suited to represent concept evolution and in some cases, e.g. real industrial environments, also suited to represent time dependent features. This paper proposes a unified approach to track evolving environments that uses a two-stages distance-based and density-based clustering algorithm. In this approach data samples are fed as input to the distance based clustering stage in an incremental, online fashion, and they are then clustered to form μ-clusters. The density-based algorithm analyses the micro-clusters to provide the final clusters: thanks to a forgetting process, clusters may emerge, drift, merge, split or disappear, hence following the evolution of the environment. This algorithm has proved to be able to detect high overlapping clusters even in multi-density distributions, making no assumption about cluster convexity. It shows fast response to data streams and good outlier rejection properties.}
}

@article{Tartakovsky2013,
  author   = {Tartakovsky, Alexander G. and Polunchenko, Aleksey S. and Sokolov, Grigory},
  journal  = {IEEE Journal of Selected Topics in Signal Processing},
  title    = {Efficient Computer Network Anomaly Detection by Changepoint Detection Methods},
  year     = {2013},
  volume   = {7},
  number   = {1},
  pages    = {4-11},
  abstract = {We consider the problem of efficient on-line anomaly detection in computer network traffic. The problem is approached statistically, as that of sequential (quickest) changepoint detection. A multi-cyclic setting of quickest change detection is a natural fit for this problem. We propose a novel score-based multi-cyclic detection algorithm. The algorithm is based on the so-called Shiryaev-Roberts procedure. This procedure is as easy to employ in practice and as computationally inexpensive as the popular Cumulative Sum chart and the Exponentially Weighted Moving Average scheme. The likelihood ratio based Shiryaev-Roberts procedure has appealing optimality properties, particularly it is exactly optimal in a multi-cyclic setting geared to detect a change occurring at a far time horizon. It is therefore expected that an intrusion detection algorithm based on the Shiryaev-Roberts procedure will perform better than other detection schemes. This is confirmed experimentally for real traces. We also discuss the possibility of complementing our anomaly detection algorithm with a spectral-signature intrusion detection system with false alarm filtering and true attack confirmation capability, so as to obtain a synergistic system.},
  keywords = {},
  doi      = {10.1109/JSTSP.2012.2233713},
  issn     = {1941-0484},
  month    = {Feb}
}

@inproceedings{Deldari2021,
  author    = {Deldari, Shohreh and Smith, Daniel V. and Xue, Hao and Salim, Flora D.},
  title     = {Time Series Change Point Detection with Self-Supervised Contrastive Predictive Coding},
  year      = {2021},
  isbn      = {9781450383127},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3442381.3449903},
  doi       = {10.1145/3442381.3449903},
  abstract  = {Change Point Detection (CPD) methods identify the times associated with changes in the trends and properties of time series data in order to describe the underlying behaviour of the system. For instance, detecting the changes and anomalies associated with web service usage, application usage or human behaviour can provide valuable insights for downstream modelling tasks. We propose a novel approach for self-supervised Time Series Change Point detection method based on Contrastive Predictive coding (TS - CP2). TS - CP2 is the first approach to employ a contrastive learning strategy for CPD by learning an embedded representation that separates pairs of embeddings of time adjacent intervals from pairs of interval embeddings separated across time. Through extensive experiments on three diverse, widely used time series datasets, we demonstrate that our method outperforms five state-of-the-art CPD methods, which include unsupervised and semi-supervised approaches. TS - CP2 is shown to improve the performance of methods that use either handcrafted statistical or temporal features by 79.4\% and deep learning-based methods by 17.0\% with respect to the F1-score averaged across the three datasets.},
  booktitle = {Proceedings of the Web Conference 2021},
  pages     = {3124-3135},
  numpages  = {12},
  keywords  = {Time series change point detection, Anomaly detection, Unsupervised learning, Contrastive learning},
  location  = {Ljubljana, Slovenia},
  series    = {WWW '21}
}

@inproceedings{Wu2021,
  author    = {Wu, Huanzhuo and He, Jia and Tömösközi, Máté and Xiang, Zuo and Fitzek, Frank H.P.},
  booktitle = {2021 IEEE Global Communications Conference (GLOBECOM)},
  title     = {In-Network Processing for Low-Latency Industrial Anomaly Detection in Softwarized Networks},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {01-07},
  abstract  = {Modern manufacturers are currently undertaking the integration of novel digital technologies - such as 5G-based wireless networks, the Internet of Things (IoT), and cloud computing - to elevate their production process to a brand new level, the level of smart factories. In the setting of a modern smart factory, time-critical applications are increasingly important to facilitate efficient and safe production. However, these applications suffer from delays in data transmission and processing due to the high density of wireless sensors and the large volumes of data that they generate. As the advent of next-generation networks has made network nodes intelligent and capable of handling multiple network functions, the increased computational power of the nodes makes it possible to offload some of the computational overhead. In this paper, we show for the first time our IA-Net-Lite industrial anomaly detection system with the novel capability of in-network data processing. IA-Net-Lite utilizes intelligent network devices to combine data transmission and processing, as well as to progressively filter redundant data in order to optimize service latency. By testing in a practical network emulator, we showed that the proposed approach can reduce the service latency by up to 40{\%}. Moreover, the benefits of our approach could potentially be exploited in other large-volume and artificial intelligence applications.},
  keywords  = {},
  doi       = {10.1109/GLOBECOM46510.2021.9685489},
  issn      = {},
  month     = {Dec}
}

@article{Bosman201514,
  title    = {Ensembles of incremental learners to detect anomalies in ad hoc sensor networks},
  journal  = {Ad Hoc Networks},
  volume   = {35},
  pages    = {14-36},
  year     = {2015},
  note     = {Special Issue on Big Data Inspired Data Sensing, Processing and Networking Technologies},
  issn     = {1570-8705},
  doi      = {https://doi.org/10.1016/j.adhoc.2015.07.013},
  url      = {https://www.sciencedirect.com/science/article/pii/S1570870515001481},
  author   = {Hedde H.W.J. Bosman and Giovanni Iacca and Arturo Tejada and Heinrich J. Wörtche and Antonio Liotta},
  keywords = {Anomaly detection, Wireless sensor networks, Online learning, Incremental learning, Ensemble methods},
  abstract = {In the past decade, rapid technological advances in the fields of electronics and telecommunications have given rise to versatile, ubiquitous decentralized embedded sensor systems with ad hoc wireless networking capabilities. Typically these systems are used to gather large amounts of data, while the detection of anomalies (such as system failures, intrusion, or unanticipated behavior of the environment) in the data (or other types or processing) is performed in centralized computer systems. In spite of the great interest that it attracts, the systematic porting and analysis of centralized anomaly detection algorithms to a decentralized paradigm (compatible with the aforementioned sensor systems) has not been thoroughly addressed in the literature. We approach this task from a new angle, assessing the viability of localized (in-node) anomaly detection based on machine learning. The main challenges we address are: (1) deploying decentralized, automated, online learning, anomaly detection algorithms within the stringent constraints of typical embedded systems; and (2) evaluating the performance of such algorithms and comparing them with that of centralized ones. To this end, we first analyze (and port) single and multi-dimensional input classifiers that are trained incrementally online and whose computational requirements are compatible with the limitations of embedded platforms. Next, we combine multiple classifiers in a single online ensemble. Then, using both synthetic and real-world datasets from different application domains, we extensively evaluate the anomaly detection performance of our algorithms and ensemble, in terms of precision and recall, and compare it to that of well-known offline, centralized machine learning algorithms. Our results show that the ensemble performs better than each individual decentralized classifier and that it can match the performance of the offline alternatives, thus showing that our approach is a viable solution to detect anomalies, even in environments with little a priori knowledge.}
}

@inproceedings{Carletti2019,
  author    = {Carletti, Mattia and Masiero, Chiara and Beghi, Alessandro and Susto, Gian Antonio},
  booktitle = {2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)},
  title     = {Explainable Machine Learning in Industry 4.0: Evaluating Feature Importance in Anomaly Detection to Enable Root Cause Analysis},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {21-26},
  abstract  = {In the past recent years, Machine Learning methodologies have been applied in countless application areas. In particular, they play a key role in enabling Industry 4.0. However, one of the main obstacles to the diffusion of Machine Learning-based applications is related to the lack of interpretability of most of these methods. In this work, we propose an approach for defining a `feature importance' in Anomaly Detection problems. Anomaly Detection is an important Machine Learning task that has an enormous applicability in industrial scenarios. Indeed, it is extremely relevant for the purpose of quality monitoring. Moreover, it is often the first step towards the design of a Machine Learning-based smart monitoring solution because Anomaly Detection can be implemented without the need of labelled data. The proposed feature importance evaluation approach is designed for Isolation Forest, one of the most commonly used algorithm for Anomaly Detection. The efficacy of the proposed method is tested on synthetic and real industrial datasets.},
  keywords  = {},
  doi       = {10.1109/SMC.2019.8913901},
  issn      = {2577-1655},
  month     = {Oct}
}

@inproceedings{Nguyen2019,
  author    = {Nguyen, Quoc Phong and Lim, Kar Wai and Divakaran, Dinil Mon and Low, Kian Hsiang and Chan, Mun Choon},
  booktitle = {2019 IEEE Conference on Communications and Network Security (CNS)},
  title     = {GEE: A Gradient-based Explainable Variational Autoencoder for Network Anomaly Detection},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {91-99},
  abstract  = {This paper looks into the problem of detecting network anomalies by analyzing NetFlow records. While many previous works have used statistical models and machine learning techniques in a supervised way, such solutions have the limitations that they require large amount of labeled data for training and are unlikely to detect zero-day attacks. Existing anomaly detection solutions also do not provide an easy way to explain or identify attacks in the anomalous traffic. To address these limitations, we develop and present GEE, a framework for detecting and explaining anomalies in network traffic. GEE comprises of two components: (i)Variational Autoencoder (VAE)- an unsupervised deep-learning technique for detecting anomalies, and (ii)a gradient-based fingerprinting technique for explaining anomalies. Evaluation of GEE on the recent UGR dataset demonstrates that our approach is effective in detecting different anomalies as well as identifying fingerprints that are good representations of these various attacks.},
  keywords  = {},
  doi       = {10.1109/CNS.2019.8802833},
  issn      = {},
  month     = {June}
}

@inproceedings{Amarasinghe2018,
  author    = {Amarasinghe, Kasun and Kenney, Kevin and Manic, Milos},
  booktitle = {2018 11th International Conference on Human System Interaction (HSI)},
  title     = {Toward Explainable Deep Neural Network Based Anomaly Detection},
  year      = {2018},
  volume    = {},
  number    = {},
  pages     = {311-317},
  abstract  = {Anomaly detection in industrial processes is crucial for general process monitoring and process health assessment. Deep Neural Networks (DNNs) based anomaly detection has received increased attention in recent work. Albeit their high accuracy, the black-box nature of DNNs is a drawback in practical deployment. Especially in industrial anomaly detection systems, explanations of DNN detected anomalies are crucial. This paper presents a framework for DNN based anomaly detection which provides explanations of detected anomalies. The framework answers the following questions during online processing: 1) “why is it an anomaly?” and 2) “what is the confidence?” Further, the framework can be used offline to evaluate the “knowledge” of the trained DNN. The framework reduces the opaqueness of the DNN based anomaly detector and thus improves human operators' trust in the algorithm. This paper implements the first steps of the presented framework on the benchmark KDD-NSL dataset for Denial of Service (DoS) attack detection. Offline DNN explanations showed that the DNN was detecting DoS attacks based on features indicating destination of connection, frequency and amount of data transferred while showing an accuracy around 97{\%}.},
  keywords  = {},
  doi       = {10.1109/HSI.2018.8430788},
  issn      = {},
  month     = {July}
}

@article{ZHANG2023120542,
  title    = {Towards deep probabilistic graph neural network for natural gas leak detection and localization without labeled anomaly data},
  journal  = {Expert Systems with Applications},
  volume   = {231},
  pages    = {120542},
  year     = {2023},
  issn     = {0957-4174},
  doi      = {https://doi.org/10.1016/j.eswa.2023.120542},
  url      = {https://www.sciencedirect.com/science/article/pii/S0957417423010448},
  author   = {Xinqi Zhang and Jihao Shi and Xinyan Huang and Fu Xiao and Ming Yang and Jiawei Huang and Xiaokang Yin and Asif {Sohail Usmani} and Guoming Chen},
  keywords = {Variation Bayesian Inference, Graph deep learning, Leakage detection, Leakage localization, Digital twin},
  abstract = {Deep learning has been widely applied to automated leakage detection and location of natural gas pipe networks. Prevalent deep learning approaches do not consider the spatial dependency of sensors, which limits leakage detection performance. Graph deep learning is a promising alternative to prevailing approaches as it can model spatial dependency. However, the challenge of collecting real-world anomaly data for training limits the accuracy and robustness of currently used graph deep learning approaches. This study proposes a deep probabilistic graph neural network in which attention-based graph neural network is built to model spatial sensor dependency. Variational Bayesian inference is integrated to model the posterior distribution of sensor dependency so that the leakage can be localized. An urban natural gas pipe network experiment is employed to construct the benchmark dataset, in which normal time-series data is applied to develop our proposed model while anomaly leakage data is used for performance comparison between our model and other state-of-the-art models. The results demonstrate that our model exhibits competitive detection accuracy (AUC) = 0.9484, while the additional uncertainty interval provides more comprehensive leakage detection information compared to state-of-the-art deep learning models. In addition, our model's posterior distribution enhances the leakage localization with the accuracy of positioning (PAc) = 0.8, which is higher than that of other state-of-the-art graph deep learning models. This study provides a comprehensive and robust alternative for subsequent decision-making to mitigate natural gas leakage from pipe networks.}
}

@article{Yang2022,
  title    = {An interpretable unsupervised Bayesian network model for fault detection and diagnosis},
  journal  = {Control Engineering Practice},
  volume   = {127},
  pages    = {105304},
  year     = {2022},
  issn     = {0967-0661},
  doi      = {https://doi.org/10.1016/j.conengprac.2022.105304},
  url      = {https://www.sciencedirect.com/science/article/pii/S0967066122001502},
  author   = {Wei-Ting Yang and Marco S. Reis and Valeria Borodin and Michel Juge and Agnès Roussy},
  keywords = {Bayesian Network (BN), eXplanatory Artificial Intelligence (XAI), Fault detection, Fault diagnosis, Interpretable machine learning},
  abstract = {Process monitoring is a critical activity in manufacturing industries. A wide variety of data-driven approaches have been developed and employed for fault detection and fault diagnosis. Analyzing the existing process monitoring schemes, prediction accuracy of the process status is usually the primary focus while the explanation (diagnosis) of a detected fault is relegated to a secondary role. In this paper, an interpretable unsupervised machine learning model based on Bayesian Networks (BN) is proposed to be the fundamental model supporting the process monitoring scheme. The proposed methodology is aligned with the recent efforts of eXplanatory Artificial Intelligence (XAI) for knowledge induction and decision making, now brought to the scope of advanced process monitoring. A BN is capable of combining data-driven induction with existing domain knowledge about the process and to display the underlying causal interactions of a process system in an easily interpretable graphical form. The proposed fault detection scheme consists of two levels of monitoring. In the first level, a global index is computed and monitored to detect any deviation from normal operation conditions. In the second level, two local indices are proposed to examine the fine structure of the fault, once it is signaled at the first level. These local indices support the diagnosis of the fault, and are based on the individual unconditional and conditional distributions of the monitored variables. A new labeling procedure is also proposed to narrow down the search and identify the fault type. Unlike many existing diagnosis methods that require access to faulty data (supervised diagnosis methods), the proposed diagnosis methodology belongs to the class that only requires data under normal conditions (unsupervised diagnosis methods). The effectiveness of the proposed monitoring scheme is demonstrated and validated through simulated datasets and an industrial dataset from semiconductor manufacturing.}
}

@article{BRITO2023120860,
  title    = {Fault Diagnosis using eXplainable AI: A transfer learning-based approach for rotating machinery exploiting augmented synthetic data},
  journal  = {Expert Systems with Applications},
  volume   = {232},
  pages    = {120860},
  year     = {2023},
  issn     = {0957-4174},
  doi      = {https://doi.org/10.1016/j.eswa.2023.120860},
  url      = {https://www.sciencedirect.com/science/article/pii/S0957417423013623},
  author   = {Lucas Costa Brito and Gian Antonio Susto and Jorge Nei Brito and Marcus Antonio Viana Duarte},
  keywords = {Data augmentation, Explainable artificial intelligence, Fault diagnosis, Rotating machinery, Synthetic data, Transfer learning},
  abstract = {Due to the growing interest for increasing productivity and cost reduction in industrial environment, new techniques for monitoring rotating machinery are emerging. Artificial Intelligence (AI) is one of the approaches that has been proposed to analyze the collected data (e.g., vibration signals) providing a diagnosis of the asset’s operating condition. Three major problems hinder the application of AI models in industrial environments, being the motivation for the research: (i) impossibility or long time to obtain a sample of all operational conditions (since faults rarely happen), (ii) high cost of experts to label all acquired data (in a supervised scenario) and (iii) lack of interpretability of the models (black-boxes). To overcome these problems, a new generic and interpretable approach for classifying faults in rotating machinery based on transfer learning from augmented synthetic data to real rotating machinery is here proposed, namely FaultD-XAI (Fault Diagnosis using eXplainable AI). To provide scalability using transfer learning, synthetic vibration signals are created mimicking the characteristic behavior of failures in operation. The application of Gradient-weighted Class Activation Mapping (Grad-CAM) with 1D Convolutional Neural Network (1D CNN) allows the post hoc interpretation of results, supporting the user in decision making and increasing diagnostic confidence. The proposed approach not only obtained promising diagnostic performance but was also able to learn characteristics used by experts to identify conditions in a source domain and apply them in another target domain. The experimental results obtained on three datasets containing different mechanical faults suggest the method offers a promising approach on exploiting transfer learning, synthetic data and explainable artificial intelligence for fault diagnosis. Lastly, to guarantee reproducibility and foster research in the field, the developed dataset is made publicly available.}
}

@article{WU2024121539,
  title    = {A self-supervised anomaly detection algorithm with interpretability},
  journal  = {Expert Systems with Applications},
  volume   = {237},
  pages    = {121539},
  year     = {2024},
  issn     = {0957-4174},
  doi      = {https://doi.org/10.1016/j.eswa.2023.121539},
  url      = {https://www.sciencedirect.com/science/article/pii/S0957417423020419},
  author   = {Zhichao Wu and Xin Yang and Xiaopeng Wei and Peijun Yuan and Yuanping Zhang and Jianming Bai},
  keywords = {Anomaly detection, Self-supervised learning, Wrapped feature selection, LOF, Interpretability},
  abstract = {Identifying the abnormal samples from a data set and determining their type are two key tasks of anomaly detection. However, the existing anomaly detection algorithms are generally faced with the defects of weak generalization ability and insufficient interpretation, the core reason of which is that they cannot mine specific features for different abnormal types. In this paper, a new anomaly detection algorithm aiming at feature selection for different abnormal types is developed. Inspired by self-supervised learning, we take the stationarity of variance changes of abnormal score similarity as a pretext task and combine it with wrapped search method. Then, the features and the corresponding parameters for different abnormal types can be screened to apply to the downstream task of anomaly integration detection. To verify the efficiency of the new algorithm, we conduct two sets of experiments to compare the new algorithm with 11 classical anomaly detection and 3 clustering anomaly detection algorithms on the data sets WDBC, WPBC and Wilt from DAMI database with the evaluation measures P@n, Adj-P@n, AP, Adj-AP and AUC. The experiment results show that, both in the identification and classification on abnormal samples, all performance measures of the new algorithm are explicitly better than that of the contrastive algorithms. Also, we apply the new algorithm to the Chinese auto insurance market, and find that the results can help managers to identify the main patterns of fraudulent claims and to summarize the feature combinations of fraud behaviors. In general, the new algorithm developed in this paper has the following advantages compared with traditional algorithms: 1) It can directly capture abnormal features and realize effective recognition of abnormal types, which effectively bridge the gap between abnormal judgement and feature screening. 2) Automatic screening of abnormal features can be completed under the condition of self-updating learning optimal strategy. 3) Only a few features are extracted from all features to reveal the abnormal characteristics, which significantly improves the interpretability and generalization ability of the algorithm and its results. In a word, through the novel self-supervised design method, feature screening is skillfully integrated into the anomaly detection task, which may provide a new way for anomaly detection research.}
}

@inproceedings{Wadinger2023,
  author    = {Wadinger, Marek and Kvasnica, Michal},
  booktitle = {2023 24th International Conference on Process Control (PC)},
  title     = {Real-Time Outlier Detection with Dynamic Process Limits},
  year      = {2023},
  volume    = {},
  number    = {},
  pages     = {138-143},
  abstract  = {Anomaly detection methods are part of the systems where rare events may endanger an operation's profitability, safety, and environmental aspects. Although many state-of the-art anomaly detection methods were developed to date, their deployment is limited to the operation conditions present during the model training. Online anomaly detection brings the capability to adapt to data drifts and change points that may not be represented during model development resulting in prolonged service life. This paper proposes an online anomaly detection algorithm for existing real-time infrastructures where low-latency detection is required and novel patterns in data occur unpredictably. The online inverse cumulative distribution-based approach is introduced to eliminate common problems of offline anomaly detectors, meanwhile providing dynamic process limits to normal operation. The benefit of the proposed method is the ease of use, fast computation, and deployability as shown in two case studies of real microgrid operation data.},
  keywords  = {},
  doi       = {10.1109/PC58330.2023.10217717},
  issn      = {},
  month     = {June}
}


@inproceedings{Yamanishi2002,
  author    = {Yamanishi, Kenji and Takeuchi, Jun-ichi},
  title     = {A Unifying Framework for Detecting Outliers and Change Points from Non-Stationary Time Series Data},
  year      = {2002},
  isbn      = {158113567X},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/775047.775148},
  doi       = {10.1145/775047.775148},
  abstract  = {We are concerned with the issues of outlier detection and change point detection from a data stream. In the area of data mining, there have been increased interest in these issues since the former is related to fraud detection, rare event discovery, etc., while the latter is related to event/trend by change detection, activity monitoring, etc. Specifically, it is important to consider the situation where the data source is non-stationary, since the nature of data source may change over time in real applications. Although in most previous work outlier detection and change point detection have not been related explicitly, this paper presents a unifying framework for dealing with both of them on the basis of the theory of on-line learning of non-stationary time series. In this framework a probabilistic model of the data source is incrementally learned using an on-line discounting learning algorithm, which can track the changing data source adaptively by forgetting the effect of past data gradually. Then the score for any given data is calculated to measure its deviation from the learned model, with a higher score indicating a high possibility of being an outlier. Further change points in a data stream are detected by applying this scoring method into a time series of moving averaged losses for prediction using the learned model. Specifically we develop an efficient algorithms for on-line discounting learning of auto-regression models from time series data, and demonstrate the validity of our framework through simulation and experimental applications to stock market data analysis.},
  booktitle = {Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages     = {676-681},
  numpages  = {6},
  location  = {Edmonton, Alberta, Canada},
  series    = {KDD '02}
}

@article{Yamanishi2004,
  author   = {Yamanishi, Kenji
              and Takeuchi, Jun-ichi
              and Williams, Graham
              and Milne, Peter},
  title    = {On-Line Unsupervised Outlier Detection Using Finite Mixtures with Discounting Learning Algorithms},
  journal  = {Data Mining and Knowledge Discovery},
  year     = {2004},
  month    = {May},
  day      = {01},
  volume   = {8},
  number   = {3},
  pages    = {275-300},
  abstract = {Outlier detection is a fundamental issue in data mining, specifically in fraud detection, network intrusion detection, network monitoring, etc. SmartSifter is an outlier detection engine addressing this problem from the viewpoint of statistical learning theory. This paper provides a theoretical basis for SmartSifter and empirically demonstrates its effectiveness. SmartSifter detects outliers in an on-line process through the on-line unsupervised learning of a probabilistic model (using a finite mixture model) of the information source. Each time a datum is input SmartSifter employs an on-line discounting learning algorithm to learn the probabilistic model. A score is given to the datum based on the learned model with a high score indicating a high possibility of being a statistical outlier. The novel features of SmartSifter are: (1) it is adaptive to non-stationary sources of data; (2) a score has a clear statistical/information-theoretic meaning; (3) it is computationally inexpensive; and (4) it can handle both categorical and continuous variables. An experimental application to network intrusion detection shows that SmartSifter was able to identify data with high scores that corresponded to attacks, with low computational costs. Further experimental application has identified a number of meaningful rare cases in actual health insurance pathology data from Australia's Health Insurance Commission.},
  issn     = {1573-756X},
  doi      = {10.1023/B:DAMI.0000023676.72185.7c},
  url      = {https://doi.org/10.1023/B:DAMI.0000023676.72185.7c}
}

@inproceedings{Steenwinckel2018,
  author    = {Steenwinckel, Bram},
  editor    = {Gangemi, Aldo
               and Gentile, Anna Lisa
               and Nuzzolese, Andrea Giovanni
               and Rudolph, Sebastian
               and Maleshkova, Maria
               and Paulheim, Heiko
               and Pan, Jeff Z.
               and Alam, Mehwish},
  title     = {Adaptive Anomaly Detection and Root Cause Analysis by Fusing Semantics and Machine Learning},
  booktitle = {The Semantic Web: ESWC 2018 Satellite Events},
  year      = {2018},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {272--282},
  abstract  = {Anomaly detection (AD) systems are either manually built by experts setting thresholds on data or constructed automatically by learning from the available data through machine learning (ML). The first requires profound prior knowledge and are non-adaptive to changing environments but can perform root cause analysis (RCA) to give an understanding of the detected anomaly. The second has a huge need for data, is unable to perform RCA and is often only trained once and deployed in various contexts, leading to a lot of false positives. Fusing the prior knowledge with ML techniques could resolve the generation of these alarms and should define the causes. The primary challenges to create such a detection system are: (1) Augmenting the current ML techniques with prior knowledge to enhance the detection rate. (2) Incorporate knowledge to interpret the cause of a detected anomaly automatically. (3) Reduce of human-involvement by automating the design of detection patterns.},
  isbn      = {978-3-319-98192-5}
}

@article{Steenwinckel2021,
  title    = {FLAGS: A methodology for adaptive anomaly detection and root cause analysis on sensor data streams by fusing expert knowledge with machine learning},
  journal  = {Future Generation Computer Systems},
  volume   = {116},
  pages    = {30-48},
  year     = {2021},
  issn     = {0167-739X},
  doi      = {https://doi.org/10.1016/j.future.2020.10.015},
  url      = {https://www.sciencedirect.com/science/article/pii/S0167739X20329927},
  author   = {Bram Steenwinckel and Dieter {De Paepe} and Sander {Vanden Hautte} and Pieter Heyvaert and Mohamed Bentefrit and Pieter Moens and Anastasia Dimou and Bruno {Van Den Bossche} and Filip {De Turck} and Sofie {Van Hoecke} and Femke Ongenae},
  keywords = {Anomaly detection, Root cause analysis, Machine learning, Semantic web, Internet of Things, Fused AI, User feedback},
  abstract = {Anomalies and faults can be detected, and their causes verified, using both data-driven and knowledge-driven techniques. Data-driven techniques can adapt their internal functioning based on the raw input data but fail to explain the manifestation of any detection. Knowledge-driven techniques inherently deliver the cause of the faults that were detected but require too much human effort to set up. In this paper, we introduce FLAGS, the Fused-AI interpretabLe Anomaly Generation System, and combine both techniques in one methodology to overcome their limitations and optimize them based on limited user feedback. Semantic knowledge is incorporated in a machine learning technique to enhance expressivity. At the same time, feedback about the faults and anomalies that occurred is provided as input to increase adaptiveness using semantic rule mining methods. This new methodology is evaluated on a predictive maintenance case for trains. We show that our method reduces their downtime and provides more insight into frequently occurring problems.}
}

@article{Stauffer2021,
  author   = {Stauffer, Todd and Chastain-Knight, Denise},
  title    = {Do not let your safe operating limits leave you S-O-L (out of luck)},
  journal  = {Process Safety Progress},
  volume   = {40},
  number   = {1},
  pages    = {e12163},
  keywords = {design limits, never exceed limits, process safety information, safe operating limits, SOL exceedances, tier 3 leading indicators},
  doi      = {https://doi.org/10.1002/prs.12163},
  url      = {https://aiche.onlinelibrary.wiley.com/doi/abs/10.1002/prs.12163},
  eprint   = {https://aiche.onlinelibrary.wiley.com/doi/pdf/10.1002/prs.12163},
  abstract = {Abstract Collection and utilization of process safety metrics is an important tool for driving improved safety. Tier three leading indicators (challenges to safety system) indicate failures of process safety management systems and highlight areas that should be improved to prevent a more serious event. Safe Operating Limit (SOL) exceedances are a commonly used Tier 3 leading indicator. Surprisingly, there are many different approaches used in industry to calculate safe operating limits and to apply them. This inconsistency potentially diminishes the usefulness of SOL exceedances as an effective indicator. This paper discusses current industry practices around safe operating limits as established by a recent global benchmark survey of over 150 safety practitioners. Areas explored in the survey of SOLs include; methodology for calculating, how/where information is stored, how/when established values are reviewed and audited, usage as a leading indicator, integration with operations (training, documentation), identification and tracking of when exceedances have occurred, and actions taken on exceedance. Key results and conclusions will be presented as well as recommendations on where industry should focus on improvement.},
  year     = {2021}
}

@inproceedings{Amer2013,
  author    = {Amer, Mennatallah and Goldstein, Markus and Abdennadher, Slim},
  title     = {Enhancing One-Class Support Vector Machines for Unsupervised Anomaly Detection},
  year      = {2013},
  isbn      = {9781450323352},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2500853.2500857},
  doi       = {10.1145/2500853.2500857},
  abstract  = {Support Vector Machines (SVMs) have been one of the most successful machine learning techniques for the past decade. For anomaly detection, also a semi-supervised variant, the one-class SVM, exists. Here, only normal data is required for training before anomalies can be detected. In theory, the one-class SVM could also be used in an unsupervised anomaly detection setup, where no prior training is conducted. Unfortunately, it turns out that a one-class SVM is sensitive to outliers in the data. In this work, we apply two modifications in order to make one-class SVMs more suitable for unsupervised anomaly detection: Robust one-class SVMs and eta one-class SVMs. The key idea of both modifications is, that outliers should contribute less to the decision boundary as normal instances. Experiments performed on datasets from UCI machine learning repository show that our modifications are very promising: Comparing with other standard unsupervised anomaly detection algorithms, the enhanced one-class SVMs are superior on two out of four datasets. In particular, the proposed eta one-class SVM has shown the most promising results.},
  booktitle = {Proceedings of the ACM SIGKDD Workshop on Outlier Detection and Description},
  pages     = {8-15},
  numpages  = {8},
  keywords  = {outlier detection, one-class SVM, unsupervised anomaly detection, support vector machines, outlier score},
  location  = {Chicago, Illinois},
  series    = {ODD '13}
}

@article{Liu2014,
  author   = {Liu, Bo and Xiao, Yanshan and Yu, Philip S. and Cao, Longbing and Zhang, Yun and Hao, Zhifeng},
  journal  = {IEEE Transactions on Knowledge and Data Engineering},
  title    = {Uncertain One-Class Learning and Concept Summarization Learning on Uncertain Data Streams},
  year     = {2014},
  volume   = {26},
  number   = {2},
  pages    = {468-484},
  abstract = {This paper presents a novel framework to uncertain one-class learning and concept summarization learning on uncertain data streams. Our proposed framework consists of two parts. First, we put forward uncertain one-class learning to cope with data of uncertainty. We first propose a local kernel-density-based method to generate a bound score for each instance, which refines the location of the corresponding instance, and then construct an uncertain one-class classifier (UOCC) by incorporating the generated bound score into a one-class SVM-based learning phase. Second, we propose a support vectors (SVs)-based clustering technique to summarize the concept of the user from the history chunks by representing the chunk data using support vectors of the uncertain one-class classifier developed on each chunk, and then extend k-mean clustering method to cluster history chunks into clusters so that we can summarize concept from the history chunks. Our proposed framework explicitly addresses the problem of one-class learning and concept summarization learning on uncertain one-class data streams. Extensive experiments on uncertain data streams demonstrate that our proposed uncertain one-class learning method performs better than others, and our concept summarization method can summarize the evolving interests of the user from the history chunks.},
  keywords = {},
  doi      = {10.1109/TKDE.2012.235},
  issn     = {1558-2191},
  month    = {Feb}
}

@article{Krawczyk2015,
  author   = {Krawczyk, Bartosz
              and Wo{\'{z}}niak, Micha{\l}},
  title    = {One-class classifiers with incremental learning and forgetting for data streams with concept drift},
  journal  = {Soft Computing},
  year     = {2015},
  month    = {Dec},
  day      = {01},
  volume   = {19},
  number   = {12},
  pages    = {3387-3400},
  abstract = {One of the most important challenges for machine learning community is to develop efficient classifiers which are able to cope with data streams, especially with the presence of the so-called concept drift. This phenomenon is responsible for the change of classification task characteristics, and poses a challenge for the learning model to adapt itself to the current state of the environment. So there is a strong belief that one-class classification is a promising research direction for data stream analysis---it can be used for binary classification without an access to counterexamples, decomposing a multi-class data stream, outlier detection or novel class recognition. This paper reports a novel modification of weighted one-class support vector machine, adapted to the non-stationary streaming data analysis. Our proposition can deal with the gradual concept drift, as the introduced one-class classifier model can adapt its decision boundary to new, incoming data and additionally employs a forgetting mechanism which boosts the ability of the classifier to follow the model changes. In this work, we propose several different strategies for incremental learning and forgetting, and additionally we evaluate them on the basis of several real data streams. Obtained results confirmed the usability of proposed classifier to the problem of data stream classification with the presence of concept drift. Additionally, implemented forgetting mechanism assures the limited memory consumption, because only quite new and valuable examples should be memorized.},
  issn     = {1433-7479},
  doi      = {10.1007/s00500-014-1492-5},
  url      = {https://doi.org/10.1007/s00500-014-1492-5}
}

@article{Miao2019,
  author   = {Miao, Xuedan and Liu, Ying and Zhao, Haiquan and Li, Chunguang},
  journal  = {IEEE Transactions on Cybernetics},
  title    = {Distributed Online One-Class Support Vector Machine for Anomaly Detection Over Networks},
  year     = {2019},
  volume   = {49},
  number   = {4},
  pages    = {1475-1488},
  abstract = {Anomaly detection has attracted much attention in recent years since it plays a crucial role in many domains. Various anomaly detection approaches have been proposed, among which one-class support vector machine (OCSVM) is a popular one. In practice, data used for anomaly detection can be distributively collected via wireless sensor networks. Besides, as the data usually arrive at the nodes sequentially, online detection method that can process streaming data is preferred. In this paper, we formulate a distributed online OCSVM for anomaly detection over networks and get a decentralized cost function. To get the decentralized implementation without transmitting the original data, we use a random approximate function to replace the kernel function. Furthermore, to find an appropriate approximate dimension, we add a sparse constraint into the decentralized cost function to get another one. Then we minimize these two cost functions by stochastic gradient descent and derive two distributed algorithms. Some theoretical analysis and experiments are performed to show the effectiveness of the proposed algorithms. Experimental results on both synthetic and real datasets reveal that both of the proposed algorithms achieve low misdetection rates and high true positive rates. Compared with other state-of-the-art anomaly detection methods, the proposed distributed algorithms not only show good anomaly detection performance, but also require relatively short running time and low CPU memory consumption.},
  keywords = {},
  doi      = {10.1109/TCYB.2018.2804940},
  issn     = {2168-2275},
  month    = {April}
}

@article{Gozuacik2021,
  author   = {G{\"o}z{\"u}a{\c{c}}{\i}k, {\"O}mer
              and Can, Fazli},
  title    = {Concept learning using one-class classifiers for implicit drift detection in evolving data streams},
  journal  = {Artificial Intelligence Review},
  year     = {2021},
  month    = {Jun},
  day      = {01},
  volume   = {54},
  number   = {5},
  pages    = {3725-3747},
  abstract = {Data stream mining has become an important research area over the past decade due to the increasing amount of data available today. Sources from various domains generate a near-limitless volume of data in temporal order. Such data are referred to as data streams, and are generally nonstationary as the characteristics of data evolves over time. This phenomenon is called concept drift, and is an issue of great importance in the literature, since it makes models obsolete by decreasing their predictive performance. In the presence of concept drift, it is necessary to adapt to change in data to build more robust and effective classifiers. Drift detectors are designed to run jointly with classification models, updating them when a significant change in data distribution is observed. In this paper, we present an implicit (unsupervised) algorithm called One-Class Drift Detector (OCDD), which uses a one-class learner with a sliding window to detect concept drift. We perform a comprehensive evaluation on mostly recent 17 prevalent concept drift detection methods and an adaptive classifier using 13 datasets. The results show that OCDD outperforms the other methods by producing models with better predictive performance on both real-world and synthetic datasets.},
  issn     = {1573-7462},
  doi      = {10.1007/s10462-020-09939-x},
  url      = {https://doi.org/10.1007/s10462-020-09939-x}
}

@inproceedings{Wetzig2019,
  author    = {Wetzig, René and Gulenko, Anton and Schmidt, Florian},
  booktitle = {2019 Sixth International Conference on Internet of Things: Systems, Management and Security (IOTSMS)},
  title     = {Unsupervised Anomaly Alerting for IoT-Gateway Monitoring using Adaptive Thresholds and Half-Space Trees},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {161-168},
  abstract  = {Through increasingly powerful hardware, the computational resources of IoT-Gateways are growing, enabling more sophisticated data analytics, service deployments and virtualisation capabilities. However, the difficulty of ensuring high reliability of IoT-Gateways and its deployed services increases along with the complexity of digital systems. Reliable operation of such gateways and devices therefore depends on automated methods for detecting abnormal behaviour as early as possible, in order to remediate the situation before the complete failure of a system component. We propose an unsupervised anomaly detection algorithm by extending the concept of Half-Space Trees through online adaptive thresholds for real-time computation. The anomaly detector consumes multidimensional time series data from an external monitoring component and is fixed in computational complexity to support real-time operation. In order to determine valuable hyperparameters, we propose a data stream and anomaly simulation system, providing options for pattern induced load simulations and different types of anomalies. Further, we evaluate the anomaly detection method on monitoring data originating from a deployment of the open source software Project Clearwater, a lightweight implementation of the IP-Multimedia Subsystem capable of running on VMs with limited resources. Results show the applicability of Half-Space Tree based anomaly detection with high detection rates (99.4\%) and low number of false alarms (<; 3\%).},
  keywords  = {},
  doi       = {10.1109/IOTSMS48152.2019.8939201},
  issn      = {},
  month     = {Oct}
}

@article{Lyu2020,
  author   = {Lyu, Yanxia and Li, Wenjie and Wang, Yue and Sun, Siqi and Wang, Cuirong},
  title    = {RMHSForest: Relative Mass and Half-Space Tree Based Forest for Anomaly Detection},
  journal  = {Chinese Journal of Electronics},
  volume   = {29},
  number   = {6},
  pages    = {1093-1101},
  keywords = {pattern clustering, security of data, trees (mathematics), AUC, data set, relative mass estimation, popular anomaly detection algorithms, mass distribution, augmented mass, local anomaly, halfspace tree, local anomalies, global anomalies, ensemble anomaly detection method, half-space tree, RMHSForest, Relative mass, Half-space tree, Anomaly detection, Ensemble methods},
  doi      = {https://doi.org/10.1049/cje.2020.09.010},
  abstract = {Anomaly detection refers to identify the true anomalies from a given data set. We present an ensemble anomaly detection method called Relative mass and half-space tree based forest (RMHSForest), which detect anomalies, including global and local anomalies, based on relative mass estimation and halfspace tree. Different from density or distance based measure, RMHSForest utilizes a novel relative mass estimation to improve the detection of local anomaly. Meanwhile, half-space tree based on augmented mass can estimate a mass distribution efficiently without density or distance calculations or clustering. Our empirical results show that RMHSForest outperforms the current popular anomaly detection algorithms in terms of AUC and processing time in the test data sets.},
  year     = {2020}
}

@article{Wel62,
  author    = { B. P.   Welford },
  title     = {Note on a Method for Calculating Corrected Sums of Squares and Products},
  journal   = {Technometrics},
  volume    = {4},
  number    = {3},
  pages     = {419-420},
  year      = {1962},
  publisher = {Taylor & Francis},
  doi       = {10.1080/00401706.1962.10490022},
}

@incollection{Mishra201831,
  title     = {Chapter 3 - Distributions and Models Thereof},
  editor    = {Srikanta Mishra and Akhil Datta-Gupta},
  booktitle = {Applied Statistical Modeling and Data Analytics},
  publisher = {Elsevier},
  pages     = {31-67},
  year      = {2018},
  isbn      = {978-0-12-803279-4},
  doi       = {https://doi.org/10.1016/B978-0-12-803279-4.00003-1},
  url       = {https://www.sciencedirect.com/science/article/pii/B9780128032794000031},
  author    = {Srikanta Mishra and Akhil Datta-Gupta},
  keywords  = {Distributions, Histogram, Quantile plot, Confidence limits, Fitting data},
  abstract  = {Distributions are a means of expressing uncertainty in data in terms of the range of possible values and their likelihood. Sampled data are generally represented empirically in terms of frequency plots (histograms) and/or cumulative probability (quantile) plots—where the probability of any outcome is inferred from the observed frequency over a long sequence of trials (as opposed to being based on subjective judgment).}
}

@article{Genz2000,
  author  = {Genz, Alan},
  year    = {2000},
  month   = {05},
  pages   = {},
  title   = {Numerical Computation Of Multivariate Normal Probabilities},
  volume  = {1},
  journal = {Journal of Computational and Graphical Statistics},
  doi     = {10.1080/10618600.1992.10477010}
}

@article{IGLESIASVAZQUEZ2023120994,
  title    = {Anomaly detection in streaming data: A comparison and evaluation study},
  journal  = {Expert Systems with Applications},
  volume   = {233},
  pages    = {120994},
  year     = {2023},
  issn     = {0957-4174},
  doi      = {https://doi.org/10.1016/j.eswa.2023.120994},
  url      = {https://www.sciencedirect.com/science/article/pii/S0957417423014963},
  author   = {Félix {Iglesias Vázquez} and Alexander Hartl and Tanja Zseby and Arthur Zimek},
  keywords = {Anomaly detection, Outlier detection, Streaming data, Concept drift},
  abstract = {The detection of anomalies in streaming data faces complexities that make traditional static methods unsuitable due to computational costs and nonstationarity. We test and evaluate eight state of the art algorithms against prominent challenges related to streaming data. Results show insights regarding accuracy, memory-dependency, parameterization, and pre-knowledge exploitation, thus revealing the high impact of some data characteristics to establish a most appropriate algorithm, namely: locality (i.e., whether outlierness is relative to local contexts), relativeness (i.e., if past data defines outlierness), and concept drift (if it is expected, its intensity and frequency). In most applied cases, such factors can be inferred in advance through the use of historical data and domain knowledge. Assuming the viability of the studied methods in terms of time efficiency, this work discloses key findings to achieve optimal designs of streaming data anomaly detection in real-life applications.}
}

@article{Ruff2021,
  author   = {Ruff, Lukas and Kauffmann, Jacob R. and Vandermeulen, Robert A. and Montavon, Grégoire and Samek, Wojciech and Kloft, Marius and Dietterich, Thomas G. and Müller, Klaus-Robert},
  journal  = {Proceedings of the IEEE},
  title    = {A Unifying Review of Deep and Shallow Anomaly Detection},
  year     = {2021},
  volume   = {109},
  number   = {5},
  pages    = {756-795},
  abstract = {Deep learning approaches to anomaly detection (AD) have recently improved the state of the art in detection performance on complex data sets, such as large collections of images or text. These results have sparked a renewed interest in the AD problem and led to the introduction of a great variety of new methods. With the emergence of numerous such methods, including approaches based on generative models, one-class classification, and reconstruction, there is a growing need to bring methods of this field into a systematic and unified perspective. In this review, we aim to identify the common underlying principles and the assumptions that are often made implicitly by various methods. In particular, we draw connections between classic “shallow” and novel deep approaches and show how this relation might cross-fertilize or extend both directions. We further provide an empirical assessment of major existing methods that are enriched by the use of recent explainability techniques and present specific worked-through examples together with practical advice. Finally, we outline critical open challenges and identify specific paths for future research in AD.},
  keywords = {},
  doi      = {10.1109/JPROC.2021.3052449},
  issn     = {1558-2256},
  month    = {May}
}

@article{Gama2014,
  author     = {Gama, Jo\~{a}o and \v{Z}liobaitundefined, Indrundefined and Bifet, Albert and Pechenizkiy, Mykola and Bouchachia, Abdelhamid},
  title      = {A Survey on Concept Drift Adaptation},
  year       = {2014},
  issue_date = {April 2014},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {46},
  number     = {4},
  issn       = {0360-0300},
  url        = {https://doi.org/10.1145/2523813},
  doi        = {10.1145/2523813},
  abstract   = {Concept drift primarily refers to an online supervised learning scenario when the relation between the input data and the target variable changes over time. Assuming a general knowledge of supervised learning in this article, we characterize adaptive learning processes; categorize existing strategies for handling concept drift; overview the most representative, distinct, and popular techniques and algorithms; discuss evaluation methodology of adaptive algorithms; and present a set of illustrative applications. The survey covers the different facets of concept drift in an integrated way to reflect on the existing scattered state of the art. Thus, it aims at providing a comprehensive introduction to the concept drift adaptation for researchers, industry analysts, and practitioners.},
  journal    = {ACM Comput. Surv.},
  month      = {mar},
  articleno  = {44},
  numpages   = {37},
  keywords   = {change detection, adaptive learning, data streams, Concept drift}
}

@article{Ahmad2017134,
  title    = {Unsupervised real-time anomaly detection for streaming data},
  journal  = {Neurocomputing},
  volume   = {262},
  pages    = {134-147},
  year     = {2017},
  note     = {Online Real-Time Learning Strategies for Data Streams},
  issn     = {0925-2312},
  doi      = {https://doi.org/10.1016/j.neucom.2017.04.070},
  url      = {https://www.sciencedirect.com/science/article/pii/S0925231217309864},
  author   = {Subutai Ahmad and Alexander Lavin and Scott Purdy and Zuha Agha},
  keywords = {Anomaly detection, Hierarchical Temporal Memory, Streaming data, Unsupervised learning, Concept drift, Benchmark dataset},
  abstract = {We are seeing an enormous increase in the availability of streaming, time-series data. Largely driven by the rise of connected real-time data sources, this data presents technical challenges and opportunities. One fundamental capability for streaming analytics is to model each stream in an unsupervised fashion and detect unusual, anomalous behaviors in real-time. Early anomaly detection is valuable, yet it can be difficult to execute reliably in practice. Application constraints require systems to process data in real-time, not batches. Streaming data inherently exhibits concept drift, favoring algorithms that learn continuously. Furthermore, the massive number of independent streams in practice requires that anomaly detectors be fully automated. In this paper we propose a novel anomaly detection algorithm that meets these constraints. The technique is based on an online sequence memory algorithm called Hierarchical Temporal Memory (HTM). We also present results using the Numenta Anomaly Benchmark (NAB), a benchmark containing real-world data streams with labeled anomalies. The benchmark, the first of its kind, provides a controlled open-source environment for testing anomaly detection algorithms on streaming data. We present results and analysis for a wide range of algorithms on this benchmark, and discuss future challenges for the emerging field of streaming analytics.}
}

@misc{skab2020,
  author       = {Katser, Iurii D. and Kozitsin, Vyacheslav O.},
  title        = {Skoltech Anomaly Benchmark (SKAB)},
  year         = {2020},
  publisher    = {Kaggle},
  howpublished = {\url{https://www.kaggle.com/dsv/1693952}},
  doi          = {10.34740/KAGGLE/DSV/1693952}
}

@article{Montiel2021,
  author  = {Jacob Montiel and Max Halford and Saulo Martiello Mastelini and Geoffrey Bolmier and Raphael Sourty and Robin Vaysse and Adil Zouitine and Heitor Murilo Gomes and Jesse Read and Talel Abdessalem and Albert Bifet},
  title   = {River: machine learning for streaming data in Python},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {110},
  pages   = {1--8},
  url     = {http://jmlr.org/papers/v22/20-1380.html}
}

@misc{Nogueira2014,
  author = {Fernando Nogueira},
  title  = {{Bayesian Optimization}: Open source constrained global optimization tool for {Python}},
  year   = {2014},
  url    = { https://github.com/fmfn/BayesianOptimization}
}
