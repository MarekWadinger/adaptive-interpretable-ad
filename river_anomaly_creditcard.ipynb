{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Getting an error below? <br>\n",
        "urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)>\n",
        "Solution:\n",
        "```\n",
        "$ cd \"/Applications/$(python3 --version | awk '{print $2}'| awk  -F. '{print \"Python \" $1\".\"$2}')\"\n",
        "$ sudo \"./Install Certificates.command\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9IItn_x72hq"
      },
      "outputs": [],
      "source": [
        "# Base\n",
        "import pandas as pd\n",
        "\n",
        "# Data\n",
        "import collections\n",
        "from river import datasets\n",
        "\n",
        "from river import optim\n",
        "from river import linear_model\n",
        "from river import imblearn\n",
        "from river import anomaly\n",
        "from river import neighbors\n",
        "from river import facto\n",
        "from river import naive_bayes\n",
        "from river import tree\n",
        "from river import ensemble\n",
        "from river import metrics\n",
        "from river import evaluate\n",
        "from river import preprocessing\n",
        "\n",
        "from streamz import Stream\n",
        "from streamz.river import RiverTrain, RiverPredict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JgBgrcc72Hk",
        "outputId": "dbcddc24-2adc-4ea2-cf88-eabbeaecac11"
      },
      "outputs": [],
      "source": [
        "X_y = datasets.CreditCard()\n",
        "\n",
        "counts = collections.Counter(y for _, y in X_y)\n",
        "\n",
        "for c, count in counts.items():\n",
        "    print(f'{c}: {count} ({count / sum(counts.values()):.5%})')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modify Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G380yucWUHVs"
      },
      "source": [
        "Anomaly Detectors do not have probabilities implemented therefore we use the anomaly score. Learning is supported only in unsupervised manner. Therefore, we add y=None to cover situations which may occur when trained in an ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gdv0a2RHEnOf"
      },
      "outputs": [],
      "source": [
        "class HalfSpaceTrees(anomaly.HalfSpaceTrees):\n",
        "  def learn_one(self, x, y=None):\n",
        "    return anomaly.HalfSpaceTrees.learn_one(self, x)\n",
        "  def predict_one(self, x, y=None):\n",
        "    return anomaly.HalfSpaceTrees.score_one(self, x)\n",
        "  def predict_proba_one(self, x, y=None):\n",
        "    p = anomaly.HalfSpaceTrees.score_one(self, x)\n",
        "    return {False: 1.0 - p, True: p}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6MDxDIpNtDP"
      },
      "outputs": [],
      "source": [
        "class OneClassSVM(anomaly.OneClassSVM):\n",
        "  def learn_one(self, x, y=None):\n",
        "    return anomaly.OneClassSVM.learn_one(self, x)\n",
        "  def predict_one(self, x, y=None):\n",
        "    return anomaly.OneClassSVM.score_one(self, x)\n",
        "  def predict_proba_one(self, x, y=None):\n",
        "    p = anomaly.OneClassSVM.score_one(self, x)\n",
        "    return {False: 1.0 - p, True: p}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyXcncHcGZZQ"
      },
      "outputs": [],
      "source": [
        "class VotingClassifier(ensemble.VotingClassifier):\n",
        "  def predict_proba_one(self, x):\n",
        "        if self.use_probabilities:\n",
        "            votes = (model.predict_proba_one(x) for model in self)\n",
        "        else:\n",
        "            votes = ({model.predict_one(x): 1} for model in self)\n",
        "        agg = collections.Counter()\n",
        "        for vote in votes:\n",
        "            agg.update(vote)\n",
        "        return {k: v / len(self.models) for k, v in dict(agg.most_common(2)).items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXcmne6DZ82y"
      },
      "outputs": [],
      "source": [
        "models = [\n",
        "  (\n",
        "    preprocessing.StandardScaler() |\n",
        "    imblearn.RandomUnderSampler(\n",
        "        classifier=linear_model.LogisticRegression(\n",
        "            loss=optim.losses.Log(weight_pos=5)\n",
        "        ),\n",
        "        desired_dist={0: .8, 1: .2},\n",
        "        seed=42\n",
        "    )\n",
        "  ),\n",
        "  (\n",
        "    preprocessing.StandardScaler() |\n",
        "    imblearn.RandomUnderSampler(\n",
        "      classifier=VotingClassifier([\n",
        "        linear_model.LogisticRegression(loss=optim.losses.Log(weight_pos=5)),\n",
        "        linear_model.LogisticRegression(loss=optim.losses.Log(weight_pos=5)),\n",
        "        linear_model.LogisticRegression(loss=optim.losses.Log(weight_pos=5)),\n",
        "        #neighbors.KNNClassifier(),\n",
        "        #HalfSpaceTrees(),\n",
        "        #anomaly.OneClassSVM(nu=0.2),\n",
        "        #facto.FFMClassifier(n_factors=10,intercept=.5,seed=42,),\n",
        "        #tree.HoeffdingTreeClassifier(),\n",
        "        #naive_bayes.GaussianNB()\n",
        "      ]),\n",
        "    desired_dist={0: .8, 1: .2},\n",
        "    seed=42\n",
        "    )\n",
        "  )\n",
        "      ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYQFlJg-L6zM"
      },
      "source": [
        "# Validate the performance of Voting Algorithm\n",
        "All three cels shall provide the saeme results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W2VfAO1ZUsJ",
        "outputId": "6ad803c8-8690-434e-f697-728ab1c9a397"
      },
      "outputs": [],
      "source": [
        "model = (\n",
        "    preprocessing.StandardScaler() |\n",
        "    imblearn.RandomUnderSampler(\n",
        "        classifier=linear_model.LogisticRegression(\n",
        "            loss=optim.losses.Log(weight_pos=5)\n",
        "        ),\n",
        "        desired_dist={0: .8, 1: .2},\n",
        "        seed=42\n",
        "    )\n",
        ")\n",
        "\n",
        "metric = metrics.ROCAUC()\n",
        "\n",
        "evaluate.progressive_val_score(X_y, model, metric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIAmrn6F8J9t",
        "outputId": "e31fc422-6b57-4e35-e121-7d3e4e172469"
      },
      "outputs": [],
      "source": [
        "model = (\n",
        "    preprocessing.StandardScaler() |\n",
        "    imblearn.RandomUnderSampler(\n",
        "      VotingClassifier([\n",
        "        linear_model.LogisticRegression(loss=optim.losses.Log(weight_pos=5)),\n",
        "        linear_model.LogisticRegression(loss=optim.losses.Log(weight_pos=5)),\n",
        "        linear_model.LogisticRegression(loss=optim.losses.Log(weight_pos=5)),\n",
        "      ]),\n",
        "    desired_dist={0: .8, 1: .2},\n",
        "    seed=42\n",
        "    )\n",
        ")\n",
        "\n",
        "metric = metrics.ROCAUC()\n",
        "\n",
        "evaluate.progressive_val_score(X_y, model, metric)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = (\n",
        "    preprocessing.StandardScaler() |\n",
        "    imblearn.RandomUnderSampler(\n",
        "      VotingClassifier([\n",
        "        linear_model.LogisticRegression(loss=optim.losses.Log(weight_pos=5)),\n",
        "        linear_model.LogisticRegression(loss=optim.losses.Log(weight_pos=5)),\n",
        "        linear_model.LogisticRegression(loss=optim.losses.Log(weight_pos=5)),\n",
        "      ]),\n",
        "    desired_dist={0: .8, 1: .2},\n",
        "    seed=42\n",
        "    )\n",
        ")\n",
        "metric = metrics.ROCAUC()\n",
        "\n",
        "# Evaluate the model on the training data\n",
        "# Alt. 1\n",
        "# evaluate.progressive_val_score(X_y, model, metric)\n",
        "# Alt. 2\n",
        "for x, y in X_y:\n",
        "    y_pred = model.predict_proba_one(x)\n",
        "    metric = metric.update(y, y_pred)\n",
        "    model = model.learn_one(x, y)\n",
        "    \n",
        "metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Streamz Anomaly Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from river import anomaly\n",
        "from streamz import Stream\n",
        "from streamz.river import RiverTrain, RiverPredict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stream"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Update RiverTrain and RiverPredict to work with supervised models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RiverTrain(Stream):\n",
        "\n",
        "    def __init__(self, model, metric=None, pass_model=False, **kwargs):\n",
        "        \"\"\"\n",
        "\n",
        "        If metric and pass_model are both defaults, this is effectively\n",
        "        a sink.\n",
        "\n",
        "        :param model: river model or pipeline\n",
        "        :param metric: river metric\n",
        "            If given, it is emitted on every sample\n",
        "        :param pass_model: bool\n",
        "            If True, the (updated) model if emitted for each sample\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self.model = model\n",
        "        if pass_model and metric is not None:\n",
        "            raise TypeError\n",
        "        self.pass_model = pass_model\n",
        "        self.metric = metric\n",
        "\n",
        "    def update(self, x, who=None, metadata=None):\n",
        "        \"\"\"\n",
        "        :param x: tuple\n",
        "            (x, [y[, w]) floats for single sample. Include\n",
        "        \"\"\"\n",
        "        \n",
        "        if self.metric:\n",
        "            if len(x) > 1:\n",
        "                yp = self.model.predict_proba_one(x[0])\n",
        "                weights = x[2] if len(x) > 2 else 1.0\n",
        "                self.metric.update(x[1], yp, weights)\n",
        "            else:\n",
        "                raise RuntimeError(\"Metric specified but ground truth not defined. Input touple possibly (x,) not (x,y).\")\n",
        "            \n",
        "        self.model.learn_one(*x)\n",
        "        \n",
        "        if self.metric:\n",
        "            return self._emit(self.metric.get(), metadata=metadata)\n",
        "        if self.pass_model:\n",
        "            return self._emit(self.model, metadata=metadata)\n",
        "        \n",
        "        \n",
        "class RiverPredict(Stream):\n",
        "\n",
        "    def __init__(self, model, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.model = model\n",
        "\n",
        "    def update(self, x, who=None, metadata=None):\n",
        "        out = self.model.predict_one(x[0])\n",
        "        return self._emit(out, metadata=metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from river import preprocessing, imblearn, linear_model, optim\n",
        "\n",
        "model = (\n",
        "    preprocessing.StandardScaler() |\n",
        "    imblearn.RandomUnderSampler(\n",
        "      VotingClassifier([\n",
        "        linear_model.LogisticRegression(loss=optim.losses.Log(weight_pos=5)),\n",
        "        linear_model.LogisticRegression(loss=optim.losses.Log(weight_pos=5)),\n",
        "        linear_model.LogisticRegression(loss=optim.losses.Log(weight_pos=5)),\n",
        "      ]),\n",
        "    desired_dist={0: .8, 1: .2},\n",
        "    seed=42\n",
        "    )\n",
        ")\n",
        "metric = metrics.ROCAUC()\n",
        "\n",
        "l = []\n",
        "s = Stream()\n",
        "# Stream pipeline for model's training\n",
        "s_train = RiverTrain(model, metric=metric)\n",
        "# Process training data for model's training\n",
        "s.map(lambda x: (x,) if not isinstance(x, tuple) else x).connect(s_train)\n",
        "# Example DataFrame\n",
        "ex = pd.DataFrame({'x': [0.5], 'y': [0.5]})\n",
        "# Stream pipeline for model's prediction\n",
        "s_pred = RiverPredict(model)\n",
        "\n",
        "t = s.connect(s_pred)\n",
        "#p = s_pred.sink(print)\n",
        "\n",
        "r = s_train.sink(l.append)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "s.visualize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for x, y in X_y:\n",
        "    s.emit((x,y))\n",
        "metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Unsupervised learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class OneClassSVM(anomaly.OneClassSVM):\n",
        "  def learn_one(self, x, y=None):\n",
        "    return anomaly.OneClassSVM.learn_one(self, x)\n",
        "  def predict_one(self, x, y=None):\n",
        "    return anomaly.OneClassSVM.score_one(self, x)\n",
        "  def predict_proba_one(self, x, y=None):\n",
        "    p = anomaly.OneClassSVM.score_one(self, x)\n",
        "    return {False: 1.0 - p, True: p}\n",
        "  \n",
        "model = OneClassSVM()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from river import preprocessing, imblearn, linear_model, optim\n",
        "\n",
        "model = (\n",
        "    preprocessing.StandardScaler() |\n",
        "      imblearn.RandomUnderSampler(VotingClassifier([\n",
        "        #linear_model.LogisticRegression(loss=optim.losses.Log(weight_pos=5)),\n",
        "        HalfSpaceTrees(),\n",
        "        OneClassSVM()\n",
        "      ]),desired_dist={0: .8, 1: .2},\n",
        "    seed=42\n",
        ")\n",
        ")\n",
        "\n",
        "metric = metrics.ROCAUC()\n",
        "\n",
        "s = Stream()\n",
        "# Stream pipeline for model's training\n",
        "s_train = RiverTrain(model, metric=metric)\n",
        "# Process training data for model's training\n",
        "s.map(lambda x: (x,) if not isinstance(x, tuple) else x).connect(s_train)\n",
        "# Stream pipeline for model's prediction\n",
        "s_pred = RiverPredict(model)\n",
        "\n",
        "t = s.connect(s_pred)\n",
        "#p = s_pred.sink(print)\n",
        "\n",
        "r = s_train.sink(l.append)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "s.visualize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for x, y in X_y:\n",
        "    s.emit((x, y))\n",
        "metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Coffee Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from coffee_queries import query_coffee_history, process_coffee"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "broker = \"mqtt.cloud.uiam.sk\"\n",
        "port = 1883\n",
        "topics = [\"shellies/Shelly_Kitchen-C_CoffeMachine/relay/0/power\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "coffee_history = query_coffee_history()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ThresholdFilter(anomaly.ThresholdFilter):\n",
        "  def predict_one(self, x):\n",
        "    return anomaly.ThresholdFilter.classify(self, x['power'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from river import preprocessing, imblearn, linear_model, optim\n",
        "\n",
        "model = (\n",
        "    ThresholdFilter(\n",
        "        OneClassSVM(),threshold=200\n",
        "        )\n",
        ")\n",
        "\n",
        "l = []\n",
        "\n",
        "# Streamed data source\n",
        "s = Stream.from_mqtt(broker, port, topics[0])\n",
        "# Process training data for model's training\n",
        "proc = s.map(process_coffee).map(lambda x: (x,) if not isinstance(x, tuple) else x)\n",
        "# Stream pipeline for model's training\n",
        "s_train = RiverTrain(model, pass_model=True)\n",
        "proc.connect(s_train)\n",
        "r = s_train.sink(l.append)\n",
        "# Stream pipeline for model's validation\n",
        "s_pred = RiverPredict(model)\n",
        "proc.connect(s_pred)\n",
        "s_pred.sink(print)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for x in coffee_history:\n",
        "    s.emit(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "s.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "s.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "s.visualize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Drift Detection\n",
        "Can be applied on scalar values only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qjnIL2EMCiW"
      },
      "outputs": [],
      "source": [
        "from river import drift\n",
        "\n",
        "adwin = drift.ADWIN()\n",
        "\n",
        "# Update drift detector and verify if change is detected\n",
        "for i, val in X_y:\n",
        "    _ = adwin.update(list(i.values())[1])\n",
        "    if adwin.drift_detected:\n",
        "        print(f\"Change detected at index {i}, input value: {val}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Credit Card dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_y = datasets.CreditCard()\n",
        "\n",
        "counts = collections.Counter(y for _, y in X_y)\n",
        "\n",
        "for c, count in counts.items():\n",
        "    print(f'{c}: {count} ({count / sum(counts.values()):.5%})')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame.from_dict(list(X_y.take(X_y.n_samples)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.join(pd.DataFrame(df[0].values.tolist())).drop(columns=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.sample(1000)[1].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[df['Time'] == 102572.0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "px.scatter(df.sample(10000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = anomaly.QuantileFilter(\n",
        "    anomaly.OneClassSVM(nu=0.002),\n",
        "    q=0.995\n",
        ")\n",
        "\n",
        "auc = metrics.ROCAUC()\n",
        "\n",
        "anomalies = []\n",
        "for i, (x, y) in enumerate(datasets.CreditCard().take(160000)):\n",
        "    if i > 100000:\n",
        "        score = model.score_one(x)\n",
        "        is_anomaly = model.classify(score)\n",
        "        model = model.learn_one(x)\n",
        "        auc = auc.update(y, is_anomaly)\n",
        "        \n",
        "        anomalies.append(is_anomaly)\n",
        "\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from plotly import graph_objects as go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[anomalies]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=df.index, y=df['V12'],\n",
        "    line_color='rgb(0,140,120)',\n",
        "    name='power [W]',\n",
        "))\n",
        "\n",
        "for anomaly_ in anomalies:\n",
        "  fig.add_vline(anomaly_, \n",
        "                line_color='rgba(100,0,0,0.5)', line_dash=\"dash\")\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title=\"Date and Time\",\n",
        "    showlegend=True)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collect(x):\n",
        "    return x\n",
        "def get_features(x):\n",
        "    return x\n",
        "def get_truth(x):\n",
        "    return x\n",
        "def preprocess(x):\n",
        "    return x\n",
        "def predict(x):\n",
        "    return x\n",
        "def learn(x):\n",
        "    return x\n",
        "def evaluate(x):\n",
        "    return x\n",
        "def store(x):\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "s = Stream()\n",
        "s.map(collect).map(preprocess).sink(print)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.1 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1 (v3.10.1:2cd268a3a9, Dec  6 2021, 14:28:59) [Clang 13.0.0 (clang-1300.0.29.3)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "3687c152e6c0e1eeeaff2a3b00d71d22322a3217307c0c25275bf60fac6f7cb1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
