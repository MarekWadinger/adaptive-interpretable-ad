{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install influxdb-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "\n",
    "def query_coffee_history():\n",
    "    # You can generate an API token from the \"API Tokens Tab\" in the UI\n",
    "    token = \"Y2nr_V73MfQqmotuaeReBnRnuPDihdKm-RCSFRwfyFhlxx4b7YjUkzBokDrhV3q6G2ib-Arknf6e9itL9ROJDg==\"\n",
    "    org = \"uiam\"\n",
    "    bucket = \"mqtt\"\n",
    "\n",
    "    with InfluxDBClient(url=\"https://influxdb.cloud.uiam.sk\", token=token, org=org) as client:\n",
    "        query = '''\n",
    "        from(bucket: \"mqtt\") \n",
    "            |> range(start: 2021-05-22T23:30:00Z) \n",
    "            |> filter(fn: (r) => r._measurement == \"shellies\" and r._field == \"power\" and r.device == \"Shelly_Kitchen-C_CoffeMachine/relay/0\")'''\n",
    "        tables = client.query_api().query(query, org=org)\n",
    "        client.close()\n",
    "    \n",
    "    l = []\n",
    "    for table in tables:\n",
    "        for record in table.records:\n",
    "            l.append({'time': str(record.get_time()),\n",
    "                      'power': record.get_value()})\n",
    "        \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = query_coffee_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"coffee_history.json\", \"w\") as final:\n",
    "   json.dump(l, final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MQTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install paho-mqtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/eclipse/paho.mqtt.python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broker = \"mqtt.cloud.uiam.sk\"\n",
    "port = 1883\n",
    "topics = [\"shellies/Shelly_Kitchen-C_CoffeMachine/relay/0/power\"]\n",
    "client_id = \"Smartphone\"\n",
    "username = 'admin'\n",
    "password = 'kefxo5-kugjEj-qodboc'\n",
    "auth = {'username': username, 'password': password}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paho.mqtt.subscribe as subscribe\n",
    "\n",
    "topics = ['shellies/#']\n",
    "topics = [\"shellies/Shelly_Kitchen-C_CoffeMachine/relay/0/power\"]\n",
    "\n",
    "m = subscribe.simple(topics, hostname=broker, retained=False, msg_count=2, client_id=client_id, clean_session=True)\n",
    "for a in m:\n",
    "    print(a.topic)\n",
    "    print(a.timestamp)\n",
    "    print(a.payload.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(a.payload.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paho.mqtt.subscribe as subscribe\n",
    "\n",
    "def print_msg(client, userdata, message):\n",
    "    print(\"%s : %s\" % (message.topic, message.payload))\n",
    "\n",
    "subscribe.callback(print_msg, topics, hostname=broker, client_id=client_id, clean_session=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paho.mqtt.client as mqtt\n",
    "\n",
    "# The callback for when the client receives a CONNACK response from the server.\n",
    "def on_connect(client, userdata, flags, rc):\n",
    "    print(\"Connected with result code \"+str(rc))\n",
    "\n",
    "    # Subscribing in on_connect() means that if we lose the connection and\n",
    "    # reconnect then subscriptions will be renewed.\n",
    "    client.subscribe(topics)\n",
    "\n",
    "# The callback for when a PUBLISH message is received from the server.\n",
    "def on_message(client, userdata, msg):\n",
    "    print(msg.topic+\" \"+str(msg.payload.decode()))\n",
    "\n",
    "client = mqtt.Client(client_id, clean_session=True)\n",
    "client.on_connect = on_connect\n",
    "client.on_message = on_message\n",
    "\n",
    "client.connect(broker, port, keepalive=6)\n",
    "\n",
    "# Blocking call that processes network traffic, dispatches callbacks and\n",
    "# handles reconnecting.\n",
    "# Other loop*() functions are available that give a threaded interface and a\n",
    "# manual interface.\n",
    "client.loop_forever()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file = open('coffee_history.json')\n",
    "data_cof = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from river import linear_model, metrics, evaluate, preprocessing, datasets, optim, imblearn, anomaly, compose\n",
    "from streamz import Stream\n",
    "#####################################################\n",
    "model_batch_LR = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    linear_model.LogisticRegression()\n",
    ")\n",
    "\n",
    "metric_batch_LR = metrics.F1()\n",
    "\n",
    "\n",
    "#####################################################\n",
    "model_strm_LR = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    linear_model.LogisticRegression()\n",
    ")\n",
    "\n",
    "metric_strm_LR = metrics.F1()\n",
    "\n",
    "\n",
    "\n",
    "##### teach batch models\n",
    "batch_size = 12500\n",
    "#batch_size = 20000\n",
    "\n",
    "x = pd.DataFrame(data_cof[0:batch_size])\n",
    "model_batch_LR.learn_many(x, x['power'] > 200)\n",
    "\n",
    "for row in data_cof[0:batch_size]:\n",
    "  y = 1 if row['power'] > 200 else 0\n",
    "  score = model_strm_LR.predict_one(row)\n",
    "  #model_strm_LR.quantile.update(score)\n",
    "  #print(y)\n",
    "  #pred = model_strm_LR.predict_one(row)\n",
    "  #print(pred)\n",
    "  model_strm_LR.learn_one(row, y)\n",
    "  #model_batch_SVM.learn_one(row)\n",
    "  ### tu sa z nejakeho bud uci zle, alebo mam zle implementovanu streamz pipelinu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data_cof[batch_size:-1]:\n",
    "    y = 1 if row['power'] > 200 else 0\n",
    "    y_pred = model_batch_LR.predict_one(row)\n",
    "    metric_batch_LR.update(y, y_pred)\n",
    "    y_pred = model_strm_LR.predict_one(row)\n",
    "    metric_strm_LR.update(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_batch_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_strm_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_batch_LR.predict_one(data_cof[batch_size+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_strm_LR.predict_one(data_cof[batch_size+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MQTT with Streamz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamz import Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_coffee_present(x):\n",
    "    return {'power': x.payload.decode()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"shellies/Shelly3EM-Main-Switchboard-C/emeter/0/energy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Stream.from_mqtt(broker, port, topics[0])\n",
    "\n",
    "s.map(process_coffee_present).sink(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1 (v3.10.1:2cd268a3a9, Dec  6 2021, 14:28:59) [Clang 13.0.0 (clang-1300.0.29.3)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3687c152e6c0e1eeeaff2a3b00d71d22322a3217307c0c25275bf60fac6f7cb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
