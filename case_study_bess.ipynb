{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "# Plot\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Data\n",
    "import collections\n",
    "from river import datasets\n",
    "\n",
    "# Tools\n",
    "from river import utils\n",
    "from river import stats\n",
    "from river import anomaly\n",
    "from river import compose\n",
    "from river import *\n",
    "\n",
    "# Stream\n",
    "from streamz import Stream\n",
    "from streamz.river import RiverTrain, RiverPredict\n",
    "\n",
    "# Real Thresh\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/marekwadinger/Documents/PhD/Teach/2022-2023/batch_data_processing/exams/data/data_BESS_INV.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.time = pd.to_datetime(df.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('time')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get outside temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_dates = df.index[df['Outside Temperature'].isna()]\n",
    "\n",
    "try:\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive?hourly=temperature_2m&timezone=Europe%2FBerlin\"\n",
    "    pos = {'longitude': '49.04', 'latitude': '19.72'}\n",
    "    date_span = {'start_date': na_dates[1].strftime('%Y-%m-%d'), \n",
    "                'end_date': na_dates[-1].strftime('%Y-%m-%d')}\n",
    "\n",
    "    params={**pos, **date_span}\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    df_out_temp = pd.DataFrame(response.json()['hourly'])\n",
    "    df_out_temp.time = pd.to_datetime(df_out_temp.time, utc=True)\n",
    "    df_out_temp = df_out_temp.set_index('time')['temperature_2m']\n",
    "    # Scale\n",
    "    min_temp = -15\n",
    "    max_temp = 50\n",
    "    range_temp = max_temp - min_temp\n",
    "\n",
    "    df_out_temp = (df_out_temp - min_temp) / range_temp\n",
    "    # Rasample\n",
    "    df_out_temp = df_out_temp.resample('1t').interpolate()\n",
    "    # Combine\n",
    "    df['Outside Temperature'] = df['Outside Temperature'].combine_first(df_out_temp)\n",
    "except:\n",
    "    df = df.drop(columns='Outside Temperature', errors='ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test TimeRolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ = []\n",
    "std_ = []\n",
    "rmean = utils.TimeRolling(stats.Mean(), period=dt.timedelta(hours=1,\n",
    "                                                            minutes=30))\n",
    "rvar = utils.TimeRolling(stats.Var(), \n",
    "                          period=dt.timedelta(hours=1, minutes=30))\n",
    "\n",
    "col = 'Inverter Temperature'\n",
    "for t, x in df.iterrows():\n",
    "    mean_.append(rmean.update(x[col], t=t.tz_localize(None)).get())\n",
    "    std_.append((rvar.update(x[col], t=t.tz_localize(None)).get()**(1/2)))\n",
    "\n",
    "s_mean = pd.Series(mean_, index=df.index)\n",
    "s_std = pd.Series(std_, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_env_pos = s_mean + 3 * s_std\n",
    "s_env_neg = s_mean - 3 * s_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=s_env_pos.index.append(s_env_pos.index[::-1]),\n",
    "    y= pd.concat([s_env_pos, s_env_neg[::-1]]),\n",
    "    fill='toself',\n",
    "    fillcolor='rgba(100,0,80,0.2)',\n",
    "    line_color='rgba(255,255,255,0)',\n",
    "    showlegend=False,\n",
    "    name=f'Mov Mean {col}',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=s_mean.index, y=s_mean,\n",
    "    line_color='rgb(100,0,80)',\n",
    "    name=f'Mov Mean {col}',\n",
    "))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define predict_one in order to use Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class HalfSpaceTrees(anomaly.HalfSpaceTrees):\n",
    "  def predict_proba_one(self, x):\n",
    "    p = anomaly.HalfSpaceTrees.score_one(self, x)\n",
    "    return {False: 1.0 - p, True: p}\n",
    "\n",
    "class QuantileFilter(anomaly.QuantileFilter):\n",
    "  def __init__(self, anomaly_detector, q: float, protect_anomaly_detector=True):\n",
    "        super().__init__(\n",
    "            anomaly_detector=anomaly_detector,\n",
    "            protect_anomaly_detector=protect_anomaly_detector,\n",
    "            q=q\n",
    "        )\n",
    "  def predict_one(self, *args):\n",
    "    score = self.score_one(*args)\n",
    "    return score >= (self.quantile.get() or np.inf)\n",
    "  \n",
    "class ThresholdFilter(anomaly.ThresholdFilter):\n",
    "  def __init__(self, anomaly_detector, threshold: float, protect_anomaly_detector=True):\n",
    "        super().__init__(\n",
    "            anomaly_detector=anomaly_detector,\n",
    "            protect_anomaly_detector=protect_anomaly_detector,\n",
    "            threshold=threshold\n",
    "        )\n",
    "  def predict_one(self, *args):\n",
    "    score = self.score_one(*args)\n",
    "    return score >= (self.threshold or np.inf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimated Threshold using 3 sigma rule-based interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmean = utils.TimeRolling(stats.Mean(), \n",
    "                          period=dt.timedelta(hours=1, minutes=30))\n",
    "rstd = utils.TimeRolling(stats.Var(), \n",
    "                          period=dt.timedelta(hours=1, minutes=30))\n",
    "to_discard = [i for i in df.columns if i != 'SOC']\n",
    "\n",
    "#model = get_stat\n",
    "#model |= compose.FuncTransformer(get_rdev)\n",
    "model = compose.Discard(*to_discard)\n",
    "model |= ThresholdFilter(\n",
    "        HalfSpaceTrees(seed=42),\n",
    "        threshold=0.997\n",
    "    )\n",
    "\n",
    "anomaly_samples = []\n",
    "anomaly_env_pos = []\n",
    "anomaly_env_neg = []\n",
    "list_env_pos = []\n",
    "list_env_neg = []\n",
    "list_mean = []\n",
    "list_std = []\n",
    "l_p = []\n",
    "l_n = []\n",
    "scores = []\n",
    "\n",
    "for t, x in df.iterrows():\n",
    "    anomaly_samples.append(model.predict_one(x))\n",
    "    \n",
    "    # Compute moving mean and std\n",
    "    x_mean = rmean.update(x, t=t.tz_localize(None)).get()\n",
    "    list_mean.append(x_mean)\n",
    "    x_std = rstd.update(x, t=t.tz_localize(None)).get()**(1/2)\n",
    "    list_std.append(x_std)\n",
    "    # Compute probability boundaries for normal values\n",
    "    x_env_pos = (x_mean + 3 * x_std)\n",
    "    x_env_neg = (x_mean - 3 * x_std)\n",
    "    list_env_pos.append(x_env_pos)\n",
    "    list_env_neg.append(x_env_neg)\n",
    "    # Predict, whether the boundaries fall within normal behavior\n",
    "    a_env_pos = model.predict_one(x_env_pos)\n",
    "    a_env_neg = model.predict_one(x_env_neg)\n",
    "    scores.append(model.score_one(x_env_neg))\n",
    "    \n",
    "    if not a_env_pos:\n",
    "        if l_p:\n",
    "            l_p.append(l_p[-1])\n",
    "        else:\n",
    "            l_p.append(x * np.nan)   \n",
    "    elif a_env_pos:\n",
    "        if anomaly_env_pos and anomaly_env_pos[-1] == 1:\n",
    "            if model.predict_one(l_p[-1]):\n",
    "                l_p.append(l_p[-1])\n",
    "            else:\n",
    "                l_p.append(x_env_pos)\n",
    "        else:\n",
    "            l_p.append(x_env_pos)\n",
    "         \n",
    "    if not a_env_neg:\n",
    "        if l_n:\n",
    "            l_n.append(l_n[-1])\n",
    "        else:\n",
    "            l_n.append(x * np.nan)   \n",
    "    elif a_env_neg:\n",
    "        if anomaly_env_neg and anomaly_env_neg[-1] == 1:\n",
    "            if model.predict_one(l_n[-1]):\n",
    "                l_n.append(l_n[-1])\n",
    "            else:\n",
    "                l_n.append(x_env_neg)\n",
    "        else:\n",
    "            l_n.append(x_env_neg)\n",
    "            \n",
    "    anomaly_env_pos.append(a_env_pos)\n",
    "    anomaly_env_neg.append(a_env_neg)\n",
    "    \n",
    "    \n",
    "    model = model.learn_one(x)\n",
    "    \n",
    "    \n",
    "s_mean = pd.DataFrame(list_mean, index=df.index)\n",
    "s_env_pos = pd.DataFrame(list_env_pos, index=df.index)\n",
    "s_env_neg = pd.DataFrame(list_env_neg, index=df.index)\n",
    "s_n = pd.DataFrame(l_n, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Proportion of anomalous samples: \"\n",
    "      f\"{sum(anomaly_samples)/len(anomaly_samples)*100:.02f}%\\n\"\n",
    "      f\"Total number of anomalous events: \"\n",
    "      f\"{sum(pd.Series(anomaly_samples).diff().dropna() == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=s_env_pos.index.append(s_env_pos.index[::-1]),\n",
    "    y= pd.concat([s_env_pos.SOC, s_env_neg.SOC[::-1]]),\n",
    "    fill='toself',\n",
    "    fillcolor='rgba(100,0,80,0.2)',\n",
    "    line_color='rgba(255,255,255,0)',\n",
    "    showlegend=False,\n",
    "    name='Mov Mean SOC',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=s_mean.index, y=s_mean.SOC,\n",
    "    line_color='rgb(100,0,80)',\n",
    "    name='Mov Mean SOC',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df.index, y=df.SOC,\n",
    "    line_color='rgb(0,140,120)',\n",
    "    name='SOC',\n",
    "))\n",
    "\n",
    "a = pd.Series(anomaly_env_pos, index=df.index).astype(int).diff()\n",
    "for x0, x1 in zip(a[a == 1].index, a[a == -1].index):\n",
    "    fig.add_vrect(x0=x0, x1=x1, fillcolor=\"yellow\", opacity=0.25)\n",
    "\n",
    "a = pd.Series(anomaly_env_neg, index=df.index).astype(int).diff()\n",
    "for x0, x1 in zip(a[a == 1].index, a[a == -1].index):\n",
    "    fig.add_vrect(x0=x0, x1=x1, fillcolor=\"yellow\", opacity=0.25)\n",
    "    \n",
    "a = pd.Series(anomaly_samples, index=df.index).astype(int).diff()\n",
    "for x0, x1 in zip(a[a == 1].index, a[a == -1].index):\n",
    "    fig.add_vrect(x0=x0, x1=x1, fillcolor=\"red\", opacity=0.25)\n",
    "    \n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df.index, y=s_n.SOC,\n",
    "    line_color='rgb(0,0,100)', \n",
    "    name='Lower Threshold 1', fillcolor='rgba(0,0,100, 0.1)', fill=\"tozeroy\"\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df.index, y=pd.Series(anomaly_env_neg).astype(int),\n",
    "    line_color='rgb(160,0,0)',\n",
    "    name='Neg Anomaly Env',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df.index, y=scores,\n",
    "    line_color='rgb(100,100,0)',\n",
    "    name='Score',\n",
    "))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real physical threshold using Gaussian Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianScorer(anomaly.GaussianScorer):\n",
    "    def learn_one(self, x, **kwargs):\n",
    "        self.gaussian.update(x, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def score_one(self, x, t=None):\n",
    "        if self.gaussian.n_samples < self.grace_period:\n",
    "            return 0\n",
    "        return 2 * abs(self.gaussian.cdf(x) - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='hist', backend='plotly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.index < '2022-03-27']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/solar_prediction.csv\", index_col=0)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df['dev'] = (df['real'] - df['pred']).abs()\n",
    "df.dev = (df.dev - df.dev.min()) / (df.dev.max() - df.dev.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y = datasets.WaterFlow()\n",
    "df = pd.DataFrame(X_y, columns=['time', 'flow'])\n",
    "df.time = df.time.apply(lambda x: x['Time'].replace(tzinfo=None))\n",
    "df.time = pd.to_datetime(df.time)\n",
    "df = df.set_index('time')\n",
    "df.flow = (df.flow - df.flow.min()) / (df.flow.max() - df.flow.min())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.99735\n",
    "#to_discard = [i for i in df.columns if i != 'SOC']\n",
    "window = dt.timedelta(hours=24*7)\n",
    "model = GaussianScorer(\n",
    "                grace_period=10,\n",
    "                period=window\n",
    "            )\n",
    "\n",
    "model_inv = GaussianScorer(\n",
    "                grace_period=10,\n",
    "                period=window\n",
    "            )\n",
    "\n",
    "col = 'SOC'\n",
    "anomaly_samples = []\n",
    "anomaly_samples_ = []\n",
    "scores = []\n",
    "scores_ = []\n",
    "list_thresh_pos = []\n",
    "list_thresh_neg = []\n",
    "mus = []\n",
    "mus_ = []\n",
    "sigmas = []\n",
    "sigmas_ = []\n",
    "samples = []\n",
    "\n",
    "for t, x in df.iterrows():\n",
    "    t = t.tz_localize(None)\n",
    "    x = x[col]\n",
    "    score = model.score_one(x); scores.append(score)\n",
    "    samples.append(model.gaussian.n_samples)\n",
    "    is_anomaly = 1 if score > threshold else 0\n",
    "    anomaly_samples.append(is_anomaly)    \n",
    "    score_ = model_inv.score_one(-x); scores_.append(score_)\n",
    "    #anomaly_samples.append(model_inv.classify(score_))\n",
    "    is_anomaly_ = 1 if score_ > threshold else 0\n",
    "    anomaly_samples_.append(is_anomaly_)\n",
    "    \n",
    "    kwargs = {'loc': model.gaussian.mu, \n",
    "              'scale': model.gaussian.sigma}\n",
    "    sigmas.append(model.gaussian._var.get())\n",
    "    mus.append(model.gaussian.mu)\n",
    "    real_thresh = norm.ppf((threshold/2 + 0.5), **kwargs)\n",
    "    real_thresh = real_thresh if real_thresh < 1 else 1\n",
    "    list_thresh_pos.append(real_thresh)\n",
    "    \n",
    "    kwargs_inv = {'loc': model_inv.gaussian.mu, \n",
    "              'scale': model_inv.gaussian.sigma}\n",
    "    sigmas_.append(model_inv.gaussian._var.get())\n",
    "    mus_.append(model_inv.gaussian.mu)\n",
    "    real_thresh = -norm.ppf((threshold/2 + 0.5), **kwargs_inv)\n",
    "    real_thresh = real_thresh if real_thresh > 0 else 0\n",
    "    list_thresh_neg.append(real_thresh)\n",
    "    # the sample before previous is anomalous\n",
    "    if not is_anomaly or (is_anomaly and \n",
    "                          sum(anomaly_samples[-60:-1]) / \n",
    "                          len(anomaly_samples[-60:-1]) > 0.9973):\n",
    "        model = model.learn_one(x, **{'t': t})\n",
    "    if not is_anomaly_ or (is_anomaly_ and \n",
    "                          sum(anomaly_samples_[-60:-1]) / \n",
    "                          len(anomaly_samples_[-60:-1]) > 0.9973):\n",
    "        model_inv = model_inv.learn_one(-x, **{'t': t})\n",
    "    \n",
    "s_thresh_pos = pd.Series(list_thresh_pos, index=df.index)\n",
    "s_thresh_neg = pd.Series(list_thresh_neg, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_mean = pd.Series(mus, index=df.index)\n",
    "s_std = pd.Series(sigmas, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_env_pos = s_mean + 3 * s_std**0.5\n",
    "s_env_neg = s_mean - 3 * s_std**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (f\"Sliding window: {window}<br>\"\n",
    "        f\"Proportion of anomalous samples: \"\n",
    "        f\"{sum(anomaly_samples)/len(anomaly_samples)*100:.02f}%<br>\"\n",
    "        f\"Total number of anomalous events: \"\n",
    "        f\"{sum(pd.Series(anomaly_samples).diff().dropna() == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df.index, y=abs(df[col]),\n",
    "    line_color='rgb(0,140,120)',\n",
    "    name=col, showlegend=True\n",
    "))\n",
    "\n",
    "  \n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df.index, y=([1] if s_thresh_pos.max(skipna=True) < 1 \n",
    "                   else [s_thresh_pos.max(skipna=True)])*len(df),\n",
    "    line_color='rgba(100,100,100, 0)', \n",
    "    name='Threshold', legendgroup='thresh', showlegend=False\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=s_thresh_pos.index, y=s_thresh_pos,\n",
    "    line_color='rgba(100,0,0,0.25)',\n",
    "    fillcolor='rgba(100,0,0, 0.1)', fill=\"tonexty\",\n",
    "    name='Threshold', legendgroup='thresh', showlegend=True\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=s_thresh_neg.index, y=s_thresh_neg,\n",
    "    line_color='rgba(100,0,0,0.25)', \n",
    "    fillcolor='rgba(100,0,0, 0.1)', fill=\"tozeroy\",\n",
    "    name='Threshold', legendgroup='thresh', showlegend=False\n",
    "))\n",
    "\n",
    "a = pd.Series(anomaly_samples, index=df.index).astype(int).diff()\n",
    "b = a[a == 1].resample('1d').sum()\n",
    "for x0, x1 in zip(a[a == 1].index, a[a == -1].index):\n",
    "    fig.add_vrect(x0=x0, x1=x1, line_color=\"red\", fillcolor=\"red\", \n",
    "                  opacity=0.25)\n",
    "'''\n",
    "#fig.add_annotation(text=text, align='left',\n",
    "#                  xref=\"paper\", yref=\"paper\",\n",
    "#                  x=0, y=1.2, showarrow=False)\n",
    "'''\n",
    "fig.update_layout(\n",
    "    yaxis_title=\"Normalized Temperature\",\n",
    "    yaxis_title_standoff = 0,\n",
    "    yaxis_range=[0,1],\n",
    "    xaxis_tickangle=60,\n",
    "    xaxis_tickfont_size=9,\n",
    "    xaxis_tickvals=b[b > 0].index,\n",
    "    \n",
    "    font_family=\"Times New Roman\",\n",
    "    font_size=9,\n",
    "    \n",
    "    autosize=True,\n",
    "    height=90*3,\n",
    "    width=120*3,\n",
    "    margin=dict(l=40, r=15, t=0, b=0),\n",
    "    bargap=0,\n",
    "        \n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"right\",\n",
    "        x=1\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = (f\"{col.replace(' ', '_')}_\"\n",
    "             f\"{int(window.total_seconds()/60/60)}_hours_sliding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(f\"{file_name}_thresh.html\")\n",
    "fig.write_image(f\"{file_name}_thresh.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.add_trace(go.Scatter(\n",
    "    x=s_env_pos.index.append(s_env_pos.index[::-1]),\n",
    "    y= pd.concat([s_env_pos, s_env_neg[::-1]]),\n",
    "    fill='toself',\n",
    "    fillcolor='rgba(100,0,80,0.2)',\n",
    "    line_color='rgba(255,255,255,0)',\n",
    "    showlegend=False,\n",
    "    name=f'Mov Mean {col}',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=s_mean.index, y=s_mean,\n",
    "    line_color='rgb(100,0,80)',\n",
    "    name=f'Mov Mean {col}',\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(f\"{file_name}_mean.html\")\n",
    "fig.write_image(f\"{file_name}_mean.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series(anomaly_samples, index=df.index).astype(int).diff()\n",
    "for x0, x1 in zip(a[a == 1].index, a[a == -1].index):\n",
    "    fig.add_vrect(x0=x0, x1=x1, line_color=\"red\", fillcolor=\"red\", \n",
    "                  opacity=0.25)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(f\"{file_name}_anomalies.html\")\n",
    "fig.write_image(f\"{file_name}_anomalies.pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore value score relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in [*map(lambda x: x/1000, range(200, 450))]:\n",
    "    x = i\n",
    "    l.append(model.score_one(x))\n",
    "px.line(x=[*map(lambda x: x/1000, range(200, 450))],y=l)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(x):\n",
    "    return x\n",
    "\n",
    "def get_rmean(x):\n",
    "    x_ = x.copy()\n",
    "    t = x_.name.tz_localize(None)\n",
    "    if rmean._latest < t:\n",
    "        rmean.update(x_, t=t)\n",
    "    return compose.Prefixer('mean_').transform_one(rmean.get())\n",
    "\n",
    "def get_rstd(x):\n",
    "    x_ = x.copy()\n",
    "    t = x_.name.tz_localize(None)\n",
    "    if rstd._latest < t:\n",
    "        rstd.update(x_, t=t)\n",
    "        if any(rstd.get() < 0):\n",
    "            print(f'Heuston we have a problem! Var is: \\n{rstd.get()}')\n",
    "        \n",
    "    return compose.Prefixer('std_').transform_one(rstd.get())\n",
    "\n",
    "def get_stat(x):\n",
    "    return {**x , **get_rmean(x), **get_rstd(x)}\n",
    "\n",
    "def get_rdev(x):\n",
    "    in_ = get_input(x)\n",
    "    mean_ = get_rmean(x) \n",
    "    new_ = {}\n",
    "    for key in in_:\n",
    "        if f'mean_{key}' in mean_:\n",
    "            new_[key] = in_[key] - mean_[f'mean_{key}']\n",
    "\n",
    "    return {**x, **compose.Prefixer('dev_').transform_one(new_)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse Tree Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = HalfSpaceTrees(seed=42, n_trees=1, height=2,)\n",
    "for t, x in df.head(800).iterrows():\n",
    "    self = self.learn_one({\"SOC\": x.SOC})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[801].SOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 0.0\n",
    "for t in self.trees:\n",
    "    for depth, node in enumerate(t.walk({\"SOC\": df.iloc[801].SOC})):\n",
    "        score += node.r_mass * 2**depth\n",
    "        print(score)\n",
    "        if node.r_mass < self.size_limit:\n",
    "            break\n",
    "\n",
    "# Normalize the score between 0 and 1\n",
    "score /= self._max_score\n",
    "print(score, self._max_score)\n",
    "score = 1-score\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 1 - score; score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = score * self._max_score; score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk(self, x, until_leaf=True):\n",
    "        \"\"\"Iterate over the nodes of the path induced by x.\"\"\"\n",
    "        yield self\n",
    "        try:\n",
    "            yield from self.next(x).walk(x, until_leaf)\n",
    "        except KeyError:\n",
    "            if until_leaf:\n",
    "                _, node = self.most_common_path()\n",
    "                yield node\n",
    "                yield from node.walk(x, until_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(t.walk({\"SOC\": df.iloc[801].SOC}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in self.trees:\n",
    "    for depth, node in enumerate(t.walk({\"SOC\": df.iloc[801].SOC})):\n",
    "        score -= node.r_mass * 2**depth\n",
    "        print(node.r_mass, depth, node.r_mass * 2**depth)\n",
    "        if node.r_mass < self.size_limit:\n",
    "                    break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self._max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.n_trees * model.window_size * (2 ** (model.height + 1) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trees"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = anomaly.GaussianScorer()\n",
    "self_inv = anomaly.GaussianScorer()\n",
    "for t, x in df.head(1000).iterrows():\n",
    "    self = self.learn_one(None, x.SOC)\n",
    "    self_inv = self_inv.learn_one(None, -x.SOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[830].SOC; x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = self.gaussian.cdf(x); p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = self.score_one(None, x); score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'loc': self.gaussian.mu, 'scale': self.gaussian.sigma}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.ppf((score/2 + 0.5), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = self_inv.gaussian.cdf(x); p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = self_inv.score_one(None, x); score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_inv = {'loc': self_inv.gaussian.mu, 'scale': self_inv.gaussian.sigma}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.ppf((score/2 + 0.5), **kwargs_inv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look for original value for transformed threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.ppf((0.997/2 + 0.5), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-norm.ppf((0.997/2 + 0.5), **kwargs_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.997/2 - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.ppf((0.856), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1000).SOC.plot(backend='plotly')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1 (v3.10.1:2cd268a3a9, Dec  6 2021, 14:28:59) [Clang 13.0.0 (clang-1300.0.29.3)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3687c152e6c0e1eeeaff2a3b00d71d22322a3217307c0c25275bf60fac6f7cb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
