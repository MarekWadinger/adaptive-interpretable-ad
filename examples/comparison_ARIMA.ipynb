{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "from river import compose\n",
    "from river import time_series\n",
    "from river.metrics.custom import (\n",
    "    MedAE,\n",
    "    SAE,\n",
    "    MeanRollingSAE,\n",
    "    MeanRollingMAE,\n",
    "    MeanRollingMedAE,\n",
    ")\n",
    "\n",
    "sys.path.insert(1, str(Path().resolve().parent))\n",
    "from functions.compose import build_model, convert_to_nested_dict  # noqa: E402\n",
    "from functions.evaluate import build_fit_evaluate, progressive_val_predict  # noqa: E402\n",
    "\n",
    "sys.path.insert(\n",
    "    1, str(Path().resolve().parent / \"publications/ilustrate/pc2023\")\n",
    ")\n",
    "from plot_matplotlib import set_size, locator, formatter  # noqa: E402\n",
    "\n",
    "# CONSTANTS\n",
    "RANDOM_STATE = 42\n",
    "random.seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "\n",
    "# FUNCTIONS\n",
    "def get_time_features(x):\n",
    "    # time = x.pop(\"time\")\n",
    "    # ordinal = time.toordinal()\n",
    "    # hour_distances = {\n",
    "    #     hour: math.exp(-((time.hour - hour) ** 2)) for hour in range(1, 25)\n",
    "    # }\n",
    "    return {}\n",
    "\n",
    "\n",
    "def save_model(model, path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    with open(f\"{path}/{alg[0]}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "\n",
    "def save_results_y(df_ys, path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    df_ys.to_csv(f\"{path}/ys.csv\", index=False)\n",
    "\n",
    "\n",
    "# DETECTION ALGORITHMS\n",
    "detection_algorithms = [\n",
    "    (\n",
    "        \"AR\",\n",
    "        [\n",
    "            partial(compose.FuncTransformer, func=get_time_features),\n",
    "            partial(time_series.SNARIMAX, d=0, q=0),\n",
    "        ],\n",
    "        {\"SNARIMAX__p__round\": (1, 100)},\n",
    "    ),\n",
    "    (\n",
    "        \"MA\",\n",
    "        [\n",
    "            partial(compose.FuncTransformer, func=get_time_features),\n",
    "            partial(time_series.SNARIMAX, d=0, p=0),\n",
    "        ],\n",
    "        {\"SNARIMAX__q__round\": (1, 100)},\n",
    "    ),\n",
    "    (\n",
    "        \"ARI\",\n",
    "        [\n",
    "            partial(compose.FuncTransformer, func=get_time_features),\n",
    "            partial(time_series.SNARIMAX, q=0),\n",
    "        ],\n",
    "        {\n",
    "            \"SNARIMAX__p__round\": (1, 100),\n",
    "            \"SNARIMAX__d__round\": (1, 100),\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"IMA\",\n",
    "        [\n",
    "            partial(compose.FuncTransformer, func=get_time_features),\n",
    "            partial(time_series.SNARIMAX, p=0),\n",
    "        ],\n",
    "        {\n",
    "            \"SNARIMAX__d__round\": (1, 100),\n",
    "            \"SNARIMAX__q__round\": (1, 100),\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"ARIMA\",\n",
    "        [\n",
    "            partial(compose.FuncTransformer, func=get_time_features),\n",
    "            partial(time_series.SNARIMAX),\n",
    "        ],\n",
    "        {\n",
    "            \"SNARIMAX__p__round\": (1, 100),\n",
    "            \"SNARIMAX__d__round\": (0, 100),\n",
    "            \"SNARIMAX__q__round\": (1, 100),\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"SNARIMAX\",\n",
    "        [\n",
    "            partial(compose.FuncTransformer, func=get_time_features),\n",
    "            partial(time_series.SNARIMAX),\n",
    "        ],\n",
    "        {\n",
    "            \"SNARIMAX__p__round\": (0, 10),\n",
    "            \"SNARIMAX__d__round\": (0, 10),\n",
    "            \"SNARIMAX__q__round\": (0, 10),\n",
    "            \"SNARIMAX__m__round\": (1, 10080),\n",
    "            \"SNARIMAX__sp__round\": (0, 10),\n",
    "            \"SNARIMAX__sd__round\": (0, 10),\n",
    "            \"SNARIMAX__sq__round\": (0, 10),\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "# DATASETS\n",
    "df = pd.read_csv(\"data/data_BESS_norm.csv\", index_col=0)\n",
    "df.index = pd.to_datetime(df.index, utc=True)\n",
    "df = df.rename(columns={\"Avg. Cell Temperature\": \"is_anomaly\"})\n",
    "\n",
    "dataset = {\n",
    "    \"name\": \"terra\",\n",
    "    \"data\": df,\n",
    "    \"anomaly_col\": \"is_anomaly\",\n",
    "    \"drop\": None,\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    3,\n",
    "    2,\n",
    "    figsize=set_size(\"thesis\", subplots=(3 / 2.3, 2 / 2.3)),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "axs = axs.flatten()\n",
    "# RUN\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    # PREPROCESS DATA\n",
    "    df = dataset[\"data\"]\n",
    "    if isinstance(dataset[\"anomaly_col\"], str):\n",
    "        df = df.rename(columns={dataset[\"anomaly_col\"]: \"anomaly\"})\n",
    "    elif isinstance(dataset[\"anomaly_col\"], pd.Series):\n",
    "        df_y = dataset[\"anomaly_col\"]\n",
    "        df[\"anomaly\"] = df_y.rename(\"anomaly\").values\n",
    "    if dataset[\"drop\"] is not None:\n",
    "        df = df.drop(columns=dataset[\"drop\"])\n",
    "    print(\n",
    "        f\"\\n=== {dataset['name']} === [{sum(df['anomaly'])}/{len(df)}]\".ljust(\n",
    "            80, \"=\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df_ys = df[[\"anomaly\"]].copy()\n",
    "    # RUN EACH MODEL AGAINST DATASET\n",
    "    for alg_no, alg in enumerate(detection_algorithms):\n",
    "        print(f\"\\n===== {alg[0]}\".ljust(80, \"=\"))\n",
    "        # INITIALIZE OPTIMIZER\n",
    "        mod_fun = partial(\n",
    "            build_fit_evaluate,\n",
    "            alg[1],\n",
    "            df,\n",
    "            metric=MeanRollingSAE(),\n",
    "        )\n",
    "\n",
    "        # INITIALIZE METRICS\n",
    "        metrics_list = []\n",
    "\n",
    "        # TUNE HYPERPARAMETERS\n",
    "        optimizer = BayesianOptimization(\n",
    "            f=mod_fun,\n",
    "            pbounds=alg[2],\n",
    "            verbose=2,\n",
    "            random_state=RANDOM_STATE,\n",
    "            allow_duplicate_points=True,\n",
    "        )\n",
    "        logger = JSONLogger(path=f\"./.results/{dataset['name']}-{alg[0]}.log\")\n",
    "        optimizer.subscribe(Events.OPTIMIZATION_END, logger)\n",
    "        optimizer.maximize()  # Best - 25 init points\n",
    "        params = convert_to_nested_dict(optimizer.max[\"params\"])\n",
    "        print(params)\n",
    "        model = build_model(alg[1], params)\n",
    "        if hasattr(model, \"seed\"):\n",
    "            model.seed = RANDOM_STATE  # type: ignore\n",
    "        if hasattr(model, \"random_state\"):\n",
    "            model.random_state = RANDOM_STATE  # type: ignore\n",
    "        # USE TUNED MODEL\n",
    "        # PROGRESSIVE PREDICT\n",
    "        metrics = [MedAE(), MeanRollingSAE()]\n",
    "        y_pred, _ = progressive_val_predict(model, df, metrics=metrics)\n",
    "\n",
    "        # LOAD RESULTS\n",
    "        axs[alg_no].plot(df_ys.resample(\"1t\").asfreq().anomaly)\n",
    "        axs[alg_no].plot(\n",
    "            pd.DataFrame(y_pred, index=df.index).resample(\"1t\").asfreq()\n",
    "        )\n",
    "        axs[alg_no].set_ylim(0, 1)\n",
    "        axs[alg_no].set_title(\n",
    "            f\"{alg[0]} ({metrics[0].__class__.__name__}: {metrics[0].get():.2f})\\n\"\n",
    "            f\"{', '.join([f'{k}: {v}' for k,v in params['SNARIMAX'].items()])}\"\n",
    "        )\n",
    "        axs[alg_no].xaxis.set_major_locator(locator)\n",
    "        axs[alg_no].xaxis.set_major_formatter(formatter)\n",
    "        axs[alg_no].tick_params(axis=\"x\", labelrotation=50, labelsize=8)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"ARIMA_opt_results.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show frozen best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from river import compose\n",
    "from river.metrics import MAE\n",
    "\n",
    "sys.path.insert(1, str(Path().resolve().parent))\n",
    "from functions.compose import build_model, convert_to_nested_dict  # noqa: E402\n",
    "from functions.evaluate import progressive_val_predict  # noqa: E402\n",
    "\n",
    "sys.path.insert(\n",
    "    1, str(Path().resolve().parent / \"publications/ilustrate/pc2023\")\n",
    ")\n",
    "from plot_matplotlib import set_size, locator, formatter  # noqa: E402\n",
    "\n",
    "\n",
    "# DETECTION ALGORITHMS\n",
    "detection_algorithms = [\n",
    "    (\n",
    "        \"AR\",\n",
    "        [\n",
    "            partial(compose.FuncTransformer, func=get_time_features),\n",
    "            partial(time_series.SNARIMAX, d=0, q=0),\n",
    "        ],\n",
    "        {\"SNARIMAX__p__round\": 2},\n",
    "    ),\n",
    "    (\n",
    "        \"MA\",\n",
    "        [\n",
    "            partial(compose.FuncTransformer, func=get_time_features),\n",
    "            partial(time_series.SNARIMAX, d=0, p=0),\n",
    "        ],\n",
    "        {\"SNARIMAX__q__round\": 1},\n",
    "    ),\n",
    "    (\n",
    "        \"ARI\",\n",
    "        [\n",
    "            partial(compose.FuncTransformer, func=get_time_features),\n",
    "            partial(time_series.SNARIMAX, q=0),\n",
    "        ],\n",
    "        {\n",
    "            \"SNARIMAX__p__round\": 1,\n",
    "            \"SNARIMAX__d__round\": 1,\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"IMA\",\n",
    "        [\n",
    "            partial(compose.FuncTransformer, func=get_time_features),\n",
    "            partial(time_series.SNARIMAX, p=0),\n",
    "        ],\n",
    "        {\n",
    "            \"SNARIMAX__d__round\": 3,\n",
    "            \"SNARIMAX__q__round\": 1,\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"ARIMA\",\n",
    "        [\n",
    "            partial(compose.FuncTransformer, func=get_time_features),\n",
    "            partial(time_series.SNARIMAX),\n",
    "        ],\n",
    "        {\n",
    "            \"SNARIMAX__p__round\": 1,\n",
    "            \"SNARIMAX__d__round\": 3,\n",
    "            \"SNARIMAX__q__round\": 8,\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"SNARIMAX\",\n",
    "        [\n",
    "            partial(compose.FuncTransformer, func=get_time_features),\n",
    "            partial(time_series.SNARIMAX),\n",
    "        ],\n",
    "        {\n",
    "            \"SNARIMAX__p__round\": 1,\n",
    "            \"SNARIMAX__d__round\": 0,\n",
    "            \"SNARIMAX__q__round\": 0,\n",
    "            \"SNARIMAX__m__round\": 1440,\n",
    "            \"SNARIMAX__sp__round\": 2,\n",
    "            \"SNARIMAX__sd__round\": 2,\n",
    "            \"SNARIMAX__sq__round\": 0,\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "# DATASETS\n",
    "dataset = {\n",
    "    \"name\": \"terra\",\n",
    "    \"data\": df,\n",
    "    \"anomaly_col\": \"is_anomaly\",\n",
    "    \"drop\": None,\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    3,\n",
    "    2,\n",
    "    figsize=set_size(\"thesis\", subplots=(3 / 2.3, 2 / 2.3)),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "axs = axs.flatten()\n",
    "# RUN\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    # PREPROCESS DATA\n",
    "    df = dataset[\"data\"]\n",
    "    # df.index = pd.to_timedelta(\n",
    "    #     range(0, len(df)), \"T\"\n",
    "    # ) + pd.Timestamp.utcnow().replace(microsecond=0)\n",
    "    if isinstance(dataset[\"anomaly_col\"], str):\n",
    "        df = df.rename(columns={dataset[\"anomaly_col\"]: \"anomaly\"})\n",
    "    elif isinstance(dataset[\"anomaly_col\"], pd.Series):\n",
    "        df_y = dataset[\"anomaly_col\"]\n",
    "        df[\"anomaly\"] = df_y.rename(\"anomaly\").values\n",
    "    if dataset[\"drop\"] is not None:\n",
    "        df = df.drop(columns=dataset[\"drop\"])\n",
    "    print(\n",
    "        f\"\\n=== {dataset['name']} === [{sum(df['anomaly'])}/{len(df)}]\".ljust(\n",
    "            80, \"=\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df_ys = df[[\"anomaly\"]].copy()\n",
    "    # RUN EACH MODEL AGAINST DATASET\n",
    "    for alg_no, alg in enumerate(detection_algorithms):\n",
    "        print(f\"\\n===== {alg[0]}\".ljust(80, \"=\"))\n",
    "        # INITIALIZE OPTIMIZER\n",
    "        params = convert_to_nested_dict(alg[2])\n",
    "        print(params)\n",
    "        model = build_model(alg[1], params)\n",
    "        if hasattr(model, \"seed\"):\n",
    "            model.seed = RANDOM_STATE  # type: ignore\n",
    "        if hasattr(model, \"random_state\"):\n",
    "            model.random_state = RANDOM_STATE  # type: ignore\n",
    "        # USE TUNED MODEL\n",
    "        # PROGRESSIVE PREDICT\n",
    "        metrics = [\n",
    "            MedAE(),\n",
    "            MAE(),\n",
    "            MeanRollingMAE(),\n",
    "            MeanRollingMedAE(),\n",
    "            SAE(),\n",
    "            MeanRollingSAE(),\n",
    "        ]\n",
    "        y_pred, _ = progressive_val_predict(\n",
    "            model, df, metrics=metrics, **{\"period\": 5}\n",
    "        )\n",
    "\n",
    "        # LOAD RESULTS\n",
    "        axs[alg_no].plot(df_ys.resample(\"1t\").asfreq().anomaly, linewidth=0.7)\n",
    "        axs[alg_no].plot(\n",
    "            pd.DataFrame(y_pred, index=df.index).resample(\"1t\").asfreq(),\n",
    "            linewidth=0.7,\n",
    "        )\n",
    "        axs[alg_no].set_ylim(0, 1)\n",
    "        axs[alg_no].set_title(\n",
    "            f\"{alg[0]} ({metrics[0].__class__.__name__}: {metrics[0].get():.2f})\\n\"\n",
    "            f\"{', '.join([f'{k}: {v}' for k,v in params['SNARIMAX'].items()])}\"\n",
    "        )\n",
    "        axs[alg_no].xaxis.set_major_locator(locator)\n",
    "        axs[alg_no].xaxis.set_major_formatter(formatter)\n",
    "        axs[alg_no].tick_params(axis=\"x\", labelrotation=50, labelsize=8)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"ARIMA_opt_results.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
