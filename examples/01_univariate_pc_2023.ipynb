{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from river import utils, proba\n",
    "\n",
    "sys.path.insert(1, str(Path().resolve().parent))\n",
    "from server import GaussianScorer\n",
    "from functions.plot import plot_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/input/inverter_temperature.csv', index_col=0)\n",
    "df.index = pd.to_datetime(df.index, utc=True)\n",
    "col = 'Inverter Temperature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/input/average_temperature.csv', index_col=0)\n",
    "df.index = pd.to_datetime(df.index, utc=True)\n",
    "col = 'Average Cell Temperature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "THRESHOLD = 0.99735\n",
    "GRACE_PERIOD=60*24\n",
    "WINDOW = dt.timedelta(hours=24*7)\n",
    "\n",
    "model = GaussianScorer(\n",
    "    utils.TimeRolling(proba.Gaussian(), period=WINDOW),\n",
    "                grace_period=GRACE_PERIOD\n",
    "            )\n",
    "\n",
    "anomaly_samples = []\n",
    "list_thresh_pos = []\n",
    "list_thresh_neg = []\n",
    "mus = []\n",
    "sigmas = []\n",
    "samples = []\n",
    "\n",
    "for i, (t, x) in enumerate(df.iterrows()):\n",
    "    t = t.tz_localize(None)\n",
    "    x = x[col]\n",
    "    if i == 0:\n",
    "        model.gaussian.obj = model.gaussian._from_state(0, x, 1e-5, 1)\n",
    "        \n",
    "    is_anomaly = model.predict_one(x)\n",
    "    anomaly_samples.append(is_anomaly)    \n",
    "    \n",
    "    thresh_high, thresh_low = model.limit_one()\n",
    "    #thresh_high = thresh_high if thresh_high < 1 else 1\n",
    "    list_thresh_pos.append(thresh_high)\n",
    "    #thresh_low = thresh_low if thresh_low > 0 else 0\n",
    "    list_thresh_neg.append(thresh_low)\n",
    "    # the sample before previous is anomalous\n",
    "    \n",
    "    sigmas.append(model.gaussian._var.get())\n",
    "    mus.append(model.gaussian.mu)\n",
    "    \n",
    "    samples.append(model.gaussian.n_samples)\n",
    "    \n",
    "    if not is_anomaly or (sum(anomaly_samples[-300:-1]) / len(anomaly_samples[-300:-1]) > 0.9973):\n",
    "        model = model.learn_one(x, **{'t': t})\n",
    "    \n",
    "\n",
    "s_mean = pd.Series(mus, index=df.index)\n",
    "s_std = pd.Series(sigmas, index=df.index)\n",
    "\n",
    "s_env_pos = s_mean + 3 * s_std**0.5\n",
    "s_env_neg = s_mean - 3 * s_std**0.5\n",
    "\n",
    "df_out = pd.DataFrame({\"level_high\": list_thresh_pos,\n",
    "                       \"level_low\": list_thresh_neg,\n",
    "                       \"anomaly\": anomaly_samples},\n",
    "                      index= df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (f\"Sliding window: {WINDOW}\\n\"\n",
    "        f\"Proportion of anomalous samples: \"\n",
    "        f\"{sum(anomaly_samples)/len(anomaly_samples)*100:.02f}%\\n\"\n",
    "        f\"Total number of anomalous events: \"\n",
    "        f\"{sum(pd.Series(anomaly_samples).diff().dropna() == 1)}\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = (f\"Dataw_\"\n",
    "             f\"{int(WINDOW.total_seconds()/60/60)}_hours_sliding\")\n",
    "\n",
    "\n",
    "plot_limits(df[col], df_out.anomaly, df_out.level_high, df_out.level_low, \n",
    "            file_name=file_name, save=False, **{\"ser_mean\": s_mean,\n",
    "                                               \"ser_pos\": s_env_pos,\n",
    "                                               \"ser_neg\": s_env_neg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import anomaly\n",
    "from river import metrics\n",
    "import numpy as np\n",
    "from river import feature_extraction as fx\n",
    "\n",
    "\n",
    "class QuantileFilter(anomaly.QuantileFilter):\n",
    "  def __init__(self, anomaly_detector, q: float, protect_anomaly_detector=True):\n",
    "        super().__init__(\n",
    "            anomaly_detector=anomaly_detector,\n",
    "            protect_anomaly_detector=protect_anomaly_detector,\n",
    "            q=q\n",
    "        )\n",
    "  def predict_one(self, *args):\n",
    "    score = self.score_one(*args)\n",
    "    return score >= (self.quantile.get() or np.inf)\n",
    "    \n",
    "    \n",
    "model = (\n",
    "    QuantileFilter(\n",
    "        anomaly.OneClassSVM(nu=0.0001),\n",
    "    q=0.9975\n",
    "    )\n",
    "    )\n",
    "\n",
    "auc = metrics.ROCAUC()\n",
    "\n",
    "anomaly_samples = []\n",
    "scores = []\n",
    "quantiles = []\n",
    "\n",
    "for i, (t, x) in enumerate(df.iterrows()):\n",
    "    x = x.values[0]\n",
    "    score = model.score_one({'data': x}); scores.append(score)\n",
    "    is_anomaly = model.predict_one({'data': x})\n",
    "    anomaly_samples.append(is_anomaly if i > 0 else False)\n",
    "    model = model.learn_one({'data': x})\n",
    "    quantiles.append(model.quantile.get())\n",
    "    #auc = auc.update(y, is_anomaly)\n",
    "    \n",
    "#print(auc)\n",
    "\n",
    "anomalies_svm = pd.Series(anomaly_samples, index=df.index)\n",
    "\n",
    "text = (f\"Proportion of anomalous samples: \"\n",
    "        f\"{sum(anomaly_samples)/len(anomaly_samples)*100:.02f}%\\n\"\n",
    "        f\"Total number of anomalous events: \"\n",
    "        f\"{sum(pd.Series(anomaly_samples).diff().dropna() == 1)}\")\n",
    "print(text)\n",
    "\n",
    "plt.plot(df.index, scores)\n",
    "plt.plot(df.index, quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import anomaly, preprocessing\n",
    "from river import metrics\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "model = (\n",
    "    QuantileFilter(\n",
    "        anomaly.HalfSpaceTrees(window_size=50,limits={'data':(0,110)}),\n",
    "    q=0.9975\n",
    "    )\n",
    "    )\n",
    "\n",
    "auc = metrics.ROCAUC()\n",
    "\n",
    "anomaly_samples = []\n",
    "scores = []\n",
    "quantiles = []\n",
    "\n",
    "for i, (t, x) in enumerate(df.iterrows()):\n",
    "    x = x.values[0]\n",
    "    score = model.score_one({'data': x}); scores.append(score)\n",
    "    is_anomaly = model.predict_one({'data': x})\n",
    "    anomaly_samples.append(is_anomaly if i > GRACE_PERIOD else False)\n",
    "    model = model.learn_one({'data': x})\n",
    "    #auc = auc.update(y, is_anomaly)\n",
    "    quantiles.append(model.quantile.get())\n",
    "#print(auc)\n",
    "\n",
    "anomalies_tree = pd.Series(anomaly_samples, index=df.index)\n",
    "\n",
    "text = (f\"Proportion of anomalous samples: \"\n",
    "        f\"{sum(anomaly_samples)/len(anomaly_samples)*100:.02f}%\\n\"\n",
    "        f\"Total number of anomalous events: \"\n",
    "        f\"{sum(pd.Series(anomaly_samples).diff().dropna() == 1)}\")\n",
    "print(text)\n",
    "\n",
    "plt.plot(df.index, scores)\n",
    "plt.plot(df.index, quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.plot import plot_compare_anomalies\n",
    "\n",
    "df_anomalies = pd.DataFrame({\"Trees\": anomalies_tree,\n",
    "                             \"OSVM\": anomalies_svm,\n",
    "                             \"ICDF\": df_out.anomaly},\n",
    "                            index=df_out.index)\n",
    "fig = plot_compare_anomalies(df[col], df_anomalies, save=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3687c152e6c0e1eeeaff2a3b00d71d22322a3217307c0c25275bf60fac6f7cb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
