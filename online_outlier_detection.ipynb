{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "\n",
    "from dynamic_signal_limits_service import GaussianScorer\n",
    "from functions.plot import plot_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/input/inverter_temperature.csv', index_col=0)\n",
    "df.index = pd.to_datetime(df.index, utc=True)\n",
    "col = 'Inverter Temperature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/input/average_temperature.csv', index_col=0)\n",
    "df.index = pd.to_datetime(df.index, utc=True)\n",
    "col = 'Average Cell Temperature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "THRESHOLD = 0.99735\n",
    "GRACE_PERIOD=60*24\n",
    "WINDOW = dt.timedelta(hours=24*7)\n",
    "\n",
    "model = GaussianScorer(\n",
    "                grace_period=GRACE_PERIOD, # Number of samples\n",
    "                period=WINDOW,\n",
    "                #window_size=60*24*7\n",
    "                \n",
    "            )\n",
    "\n",
    "model_inv = GaussianScorer(\n",
    "                grace_period=GRACE_PERIOD,\n",
    "                period=WINDOW\n",
    "                \n",
    "            )\n",
    "\n",
    "anomaly_samples = []\n",
    "anomaly_samples_ = []\n",
    "list_thresh_pos = []\n",
    "list_thresh_neg = []\n",
    "mus = []\n",
    "mus_ = []\n",
    "sigmas = []\n",
    "sigmas_ = []\n",
    "samples = []\n",
    "times = []\n",
    "\n",
    "for i, (t, x) in enumerate(df.iterrows()):\n",
    "    start = time.perf_counter_ns()\n",
    "    t = t.tz_localize(None)\n",
    "    x = x[col]\n",
    "    if i == 0:\n",
    "        model.gaussian.obj = model.gaussian._from_state(0, x, 1e-5, 1)\n",
    "        model_inv.gaussian.obj = model_inv.gaussian._from_state(0, -x, 1e-5, 1)\n",
    "        \n",
    "    is_anomaly = model.predict_one(x)\n",
    "    anomaly_samples.append(is_anomaly)    \n",
    "\n",
    "    score_ = model_inv.score_one(-x)\n",
    "    if i > GRACE_PERIOD:\n",
    "        is_anomaly_ = 1 if score_ > THRESHOLD else 0\n",
    "    else:\n",
    "        is_anomaly_ = 0\n",
    "    is_anomaly_ = model_inv.predict_one(-x)\n",
    "    anomaly_samples_.append(is_anomaly_)\n",
    "    \n",
    "    pause = time.perf_counter_ns()\n",
    "    kwargs = {'loc': model.gaussian.mu, \n",
    "            'scale': model.gaussian.sigma}\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "        real_thresh = norm.ppf((THRESHOLD/2 + 0.5), **kwargs)\n",
    "    #real_thresh = real_thresh if real_thresh < 1 else 1\n",
    "    list_thresh_pos.append(real_thresh)\n",
    "    \n",
    "    kwargs_inv = {'loc': model_inv.gaussian.mu, \n",
    "            'scale': model_inv.gaussian.sigma}\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "        real_thresh = -norm.ppf((THRESHOLD/2 + 0.5), **kwargs_inv)\n",
    "    #real_thresh = real_thresh if real_thresh > 0 else 0\n",
    "    list_thresh_neg.append(real_thresh)\n",
    "    # the sample before previous is anomalous\n",
    "    \n",
    "    sigmas.append(model.gaussian._var.get())\n",
    "    mus.append(model.gaussian.mu)\n",
    "    \n",
    "    sigmas_.append(model_inv.gaussian._var.get())\n",
    "    mus_.append(model_inv.gaussian.mu)\n",
    "    \n",
    "    samples.append(model.gaussian.n_samples)\n",
    "    step = time.perf_counter_ns()\n",
    "    if not is_anomaly or (sum(anomaly_samples_[-300:-1]) / len(anomaly_samples_[-300:-1]) > 0.9973):\n",
    "        model = model.learn_one(x, **{'t': t})\n",
    "    if not is_anomaly_ or (sum(anomaly_samples_[-300:-1]) / len(anomaly_samples_[-300:-1]) > 0.9973):\n",
    "        model_inv = model_inv.learn_one(-x, **{'t': t})\n",
    "    times.append((time.perf_counter_ns() - step) + (pause - start))\n",
    "\n",
    "s_mean = pd.Series(mus, index=df.index)\n",
    "s_std = pd.Series(sigmas, index=df.index)\n",
    "\n",
    "s_env_pos = s_mean + 3 * s_std**0.5\n",
    "s_env_neg = s_mean - 3 * s_std**0.5\n",
    "\n",
    "df_out = pd.DataFrame({\"level_high\": list_thresh_pos,\n",
    "                       \"level_low\": list_thresh_neg,\n",
    "                       \"anomaly\": anomaly_samples},\n",
    "                      index= df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (f\"Sliding window: {WINDOW}\\n\"\n",
    "        f\"Proportion of anomalous samples: \"\n",
    "        f\"{sum(anomaly_samples)/len(anomaly_samples)*100:.02f}%\\n\"\n",
    "        f\"Total number of anomalous events: \"\n",
    "        f\"{sum(pd.Series(anomaly_samples).diff().dropna() == 1)}\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_csv(\"publications/ilustrate/pc2023/inverter/inverter_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_limits(df[col], df_out.anomaly, df_out.level_high, df_out.level_low, \n",
    "            save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import anomaly\n",
    "from river import metrics\n",
    "import numpy as np\n",
    "from river import feature_extraction as fx\n",
    "\n",
    "\n",
    "class QuantileFilter(anomaly.QuantileFilter):\n",
    "    def __init__(self, anomaly_detector, q: float, grace_period: int = 0,\n",
    "               protect_anomaly_detector=True):\n",
    "        super().__init__(\n",
    "            anomaly_detector=anomaly_detector,\n",
    "            protect_anomaly_detector=protect_anomaly_detector,\n",
    "            q=q\n",
    "        )\n",
    "        self.n = 0\n",
    "        self.grace_period = grace_period\n",
    "\n",
    "    def predict_one(self, *args):\n",
    "        score = self.score_one(*args)\n",
    "        return score >= (self.quantile.get() or np.inf)\n",
    "\n",
    "    def learn_one(self, *args):\n",
    "        self.n += 1\n",
    "        score = self.score_one(*args)\n",
    "        if self.n < self.grace_period or not self.protect_anomaly_detector or not self.classify(score):\n",
    "            self.anomaly_detector.learn_one(*args)\n",
    "        self.quantile.update(score)\n",
    "        return self\n",
    "\n",
    "    \n",
    "model = (\n",
    "    QuantileFilter(\n",
    "        anomaly.OneClassSVM(nu=0.2),\n",
    "    q=0.995,\n",
    "    grace_period=0\n",
    "    )\n",
    "    )\n",
    "\n",
    "auc = metrics.ROCAUC()\n",
    "\n",
    "anomaly_samples = []\n",
    "scores = []\n",
    "quantiles = []\n",
    "times = []\n",
    "for i, (t, x) in enumerate(df.iterrows()):\n",
    "    start = time.perf_counter_ns()\n",
    "    x = x.values[0]\n",
    "    score = model.score_one({'data': x}); scores.append(score)\n",
    "    is_anomaly = model.predict_one({'data': x})\n",
    "    anomaly_samples.append(is_anomaly if i > 0 else False)\n",
    "    model = model.learn_one({'data': x})\n",
    "    quantiles.append(model.quantile.get())\n",
    "    #auc = auc.update(y, is_anomaly)\n",
    "    times.append(time.perf_counter_ns() - start)\n",
    "#print(auc)\n",
    "\n",
    "anomalies_svm = pd.Series(anomaly_samples, index=df.index)\n",
    "\n",
    "text = (f\"Proportion of anomalous samples: \"\n",
    "        f\"{sum(anomaly_samples)/len(anomaly_samples)*100:.02f}%\\n\"\n",
    "        f\"Total number of anomalous events: \"\n",
    "        f\"{sum(pd.Series(anomaly_samples).diff().dropna() == 1)}\")\n",
    "print(text)\n",
    "\n",
    "plt.plot(df.index, scores)\n",
    "plt.plot(df.index, quantiles)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import anomaly, preprocessing\n",
    "from river import metrics\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "model = (\n",
    "    QuantileFilter(\n",
    "        anomaly.HalfSpaceTrees(window_size=50,limits={'data':(0,110)}, seed=42),\n",
    "    q=0.99\n",
    "    )\n",
    "    )\n",
    "\n",
    "auc = metrics.ROCAUC()\n",
    "\n",
    "anomaly_samples = []\n",
    "scores = []\n",
    "quantiles = []\n",
    "times = []\n",
    "for i, (t, x) in enumerate(df.iterrows()):\n",
    "    start = time.perf_counter_ns()\n",
    "    x = x.values[0]\n",
    "    score = model.score_one({'data': x}); scores.append(score)\n",
    "    is_anomaly = model.predict_one({'data': x})\n",
    "    anomaly_samples.append(is_anomaly if i > GRACE_PERIOD else False)\n",
    "    model = model.learn_one({'data': x})\n",
    "    #auc = auc.update(y, is_anomaly)\n",
    "    quantiles.append(model.quantile.get())\n",
    "    times.append(time.perf_counter_ns() - start)\n",
    "#print(auc)\n",
    "\n",
    "anomalies_tree = pd.Series(anomaly_samples, index=df.index)\n",
    "\n",
    "text = (f\"Proportion of anomalous samples: \"\n",
    "        f\"{sum(anomaly_samples)/len(anomaly_samples)*100:.02f}%\\n\"\n",
    "        f\"Total number of anomalous events: \"\n",
    "        f\"{sum(pd.Series(anomaly_samples).diff().dropna() == 1)}\")\n",
    "print(text)\n",
    "\n",
    "plt.plot(df.index, scores)\n",
    "plt.plot(df.index, quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomalies = pd.DataFrame({\"HST\": anomalies_tree,\n",
    "                             \"OSVM\": anomalies_svm,\n",
    "                             \"ICDF\": df_out.anomaly},\n",
    "                            index=df_out.index)\n",
    "df_anomalies.to_csv(\"publications/ilustrate/pc2023/inverter/comparison_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.plot import plot_compare_anomalies\n",
    "\n",
    "plot_compare_anomalies(df[col], df_anomalies, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3687c152e6c0e1eeeaff2a3b00d71d22322a3217307c0c25275bf60fac6f7cb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
